{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ce5c73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(mediation)\n",
    "library(brms)\n",
    "library(dplyr)\n",
    "library(tidyr)\n",
    "library(lme4)\n",
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049d880a",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b33d5c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long <- read.csv(\"df_RCT.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd1a9227",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "Error in `mutate()`:\nℹ In argument: `condition = ifelse(condition == 0, 0, 1)`.\nCaused by error:\n! object 'condition' not found",
     "output_type": "error",
     "traceback": [
      "Error in `mutate()`:\n",
      "ℹ In argument: `condition = ifelse(condition == 0, 0, 1)`.\n",
      "Caused by error:\n",
      "! object 'condition' not found\n",
      "     ▆\n",
      "  1. ├─... %>% distinct()\n",
      "  2. ├─dplyr::distinct(.)\n",
      "  3. ├─dplyr::filter(., !is.na(resp_value))\n",
      "  4. ├─dplyr::rename(., resp_value = max)\n",
      "  5. ├─tidyr::pivot_longer(...)\n",
      "  6. ├─dplyr::select(...)\n",
      "  7. ├─dplyr::mutate(., condition = ifelse(condition == 0, 0, 1))\n",
      "  8. ├─dplyr:::mutate.data.frame(., condition = ifelse(condition == 0, 0, 1))\n",
      "  9. │ └─dplyr:::mutate_cols(.data, dplyr_quosures(...), by)\n",
      " 10. │   ├─base::withCallingHandlers(...)\n",
      " 11. │   └─dplyr:::mutate_col(dots[[i]], data, mask, new_columns)\n",
      " 12. │     └─mask$eval_all_mutate(quo)\n",
      " 13. │       └─dplyr (local) eval()\n",
      " 14. ├─base::ifelse(condition == 0, 0, 1)\n",
      " 15. └─base::.handleSimpleError(...)\n",
      " 16.   └─dplyr (local) h(simpleError(msg, call))\n",
      " 17.     └─rlang::abort(message, class = error_class, parent = parent, call = error_call)"
     ]
    }
   ],
   "source": [
    "df_prepost <- df_long %>%\n",
    "  # ONLY use pre-intervention date\n",
    "  filter(time_point == 0) %>%\n",
    "  \n",
    "  # condition already encoded as 0 = pre-treadmill, 1 = post-treadmill\n",
    "  mutate(condition = ifelse(condition == 0, 0, 1)) %>%\n",
    "  \n",
    "  dplyr::select(\n",
    "    record_id,\n",
    "    condition,\n",
    "    all_of(outcomes),\n",
    "    matches(paste0(\"^(\", paste(resp_types, collapse = \"|\"), \")_(pre|post)_max$\")),\n",
    "    all_of(covariates)\n",
    "  ) %>%\n",
    "  \n",
    "  pivot_longer(\n",
    "    cols = matches(paste0(\"^(\", paste(resp_types, collapse = \"|\"), \")_(pre|post)_max$\")),\n",
    "    names_to      = c(\"resp_type\", \"time\", \".value\"),\n",
    "    names_pattern = \"(.+)_(pre|post)_(.+)\"\n",
    "  ) %>%\n",
    "  \n",
    "  rename(resp_value = max) %>%\n",
    "  filter(!is.na(resp_value)) %>%\n",
    "  distinct()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3aefee78",
   "metadata": {},
   "outputs": [],
   "source": [
    "View(df_prepost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0882808",
   "metadata": {},
   "source": [
    "## New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "302d22aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(dplyr)\n",
    "library(tidyr)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# LOAD DATA\n",
    "# --------------------------------------------------\n",
    "df_long <- read.csv(\"df_RCT.csv\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# VARIABLES\n",
    "# --------------------------------------------------\n",
    "\n",
    "outcomes <- c(\"fss_sum\", \"woods_sum\", \"dsq_sum\")\n",
    "\n",
    "resp_vars <- c(\n",
    "  \"mip_pre_max\", \"smip_pre_max\", \"fit_pre_max\", \"id_pre_max\", \"slopesmip_pre_max\",\n",
    "  \"sindex_pre_max\", \"pif_pre_max\", \"volume_pre_max\",\n",
    "  \"mip_post_max\", \"smip_post_max\", \"fit_post_max\", \"id_post_max\", \"slopesmip_post_max\",\n",
    "  \"pif_post_max\", \"sindex_post_max\", \"volume_post_max\",\n",
    "  \"cpet_vo2peak_absolute\", \"cpet_ve\", \"cpet_vt_peak\", \"cpet_o2pulse\",\n",
    "  \"fmd_percent\"\n",
    ")\n",
    "\n",
    "covariates <- c(\"data_age\", \"data_centimeters\", \"data_kilograms\", \"subject_female\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# STEP 1 — CENTER RESP VARIABLES & CREATE NEW COLUMNS\n",
    "# --------------------------------------------------\n",
    "\n",
    "for (v in resp_vars) {\n",
    "  if (!v %in% names(df_long)) {\n",
    "    warning(\"Variable \", v, \" not found in df_long, skipping.\")\n",
    "  } else {\n",
    "    mean_v <- mean(df_long[[v]], na.rm = TRUE)\n",
    "    new_name <- paste0(v, \"_c\")\n",
    "    df_long[[new_name]] <- df_long[[v]] - mean_v\n",
    "  }\n",
    "}\n",
    "\n",
    "# --------------------------------------------------\n",
    "# STEP 2 — CREATE df_prepost (BEST STRUCTURE)\n",
    "# 2 rows per participant: pre-treadmill (0) and post-treadmill (1)\n",
    "# USING ONLY time_point = 0 VISIT\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Helper function to rename pre/post columns to unified names\n",
    "rename_resp <- function(df, prefix) {\n",
    "  rename_at(\n",
    "    df,\n",
    "    vars(ends_with(\"_pre_max\")),\n",
    "    ~gsub(\"_pre_max\", paste0(\"_\", prefix), .)\n",
    "  ) %>%\n",
    "  rename_at(\n",
    "    vars(ends_with(\"_post_max\")),\n",
    "    ~gsub(\"_post_max\", paste0(\"_\", prefix), .)\n",
    "  )\n",
    "}\n",
    "\n",
    "# Keep ONLY time_point 0 (pre-intervention visit)\n",
    "df_baseline <- df_long %>% filter(time_point == 1)\n",
    "\n",
    "# PRE-treadmill dataset (condition = 0)\n",
    "df_pre <- df_baseline %>%\n",
    "  mutate(condition = 0) %>%\n",
    "  dplyr::select(\n",
    "    record_id, condition, all_of(outcomes), all_of(covariates),\n",
    "    matches(\"_pre_max$\"),  # original values\n",
    "    matches(\"_pre_max_c$\") # centered values\n",
    "  ) %>%\n",
    "  rename_with(~gsub(\"_pre_max\", \"\", .x), matches(\"_pre_max$\")) %>%\n",
    "  rename_with(~gsub(\"_pre_max_c\", \"_c\", .x), matches(\"_pre_max_c$\"))\n",
    "\n",
    "# POST-treadmill dataset (condition = 1)\n",
    "df_post <- df_baseline %>%\n",
    "  mutate(condition = 1) %>%\n",
    "  dplyr::select(\n",
    "    record_id, condition, all_of(outcomes), all_of(covariates),\n",
    "    matches(\"_post_max$\"),\n",
    "    matches(\"_post_max_c$\")\n",
    "  ) %>%\n",
    "  rename_with(~gsub(\"_post_max\", \"\", .x), matches(\"_post_max$\")) %>%\n",
    "  rename_with(~gsub(\"_post_max_c\", \"_c\", .x), matches(\"_post_max_c$\"))\n",
    "\n",
    "# Combine into final df_prepost\n",
    "df_prepost <- bind_rows(df_pre, df_post) %>%\n",
    "  arrange(record_id, condition)\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Export\n",
    "# --------------------------------------------------\n",
    "write.csv(df_prepost, file = \"df_prepost.csv\", row.names = FALSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae2be44",
   "metadata": {},
   "source": [
    "# Outcome Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a8cb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes <- c(\"fss_sum\", \"dsq_sum\", \"dsq_freq_sum\", \"dsq_severity_sum\", \"psqi_sum\", \"psqi_disturbances\")\n",
    "resp_vars <- c(\"mip_pre_max\", \"smip_pre_max\", \"fit_pre_max\", \"id_pre_max\", \"slopesmip_pre_max\",\n",
    "               \"sindex_pre_max\", \"pif_pre_max\", \"volume_pre_max\",\n",
    "                \"mip_post_max\",  \"smip_post_max\",\"fit_post_max\", \"id_post_max\", \"slopesmip_post_max\", \n",
    "                \"pif_post_max\", \"sindex_post_max\", \"volume_post_max\", \n",
    "                'cpet_vo2peak_absolute', \"cpet_ve\", \"cpet_vt_peak\", \"cpet_o2pulse\",  \n",
    "                \"fmd_percent\")\n",
    "resp_adjusted_vars <- c(\"mip_pre_max_percentpredict_1\", \"mip_pre_max_percentpredict_2\", \"mip_pre_max_percentpredict_3\", \"mip_pre_max_percentpredict_4\", \"mip_pre_max_percentpredict_5\", \"sindex_pre_max_percentpredict\",\n",
    "                        \"mip_post_max_percentpredict_1\", \"mip_post_max_percentpredict_2\", \"mip_post_max_percentpredict_3\", \"mip_post_max_percentpredict_4\", \"mip_post_max_percentpredict_5\", \"sindex_post_max_percentpredict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "371354aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Centering complete for variables:\n",
      " [1] \"mip_pre_max\"           \"smip_pre_max\"          \"fit_pre_max\"           \"id_pre_max\"           \n",
      " [5] \"slopesmip_pre_max\"     \"sindex_pre_max\"        \"pif_pre_max\"           \"volume_pre_max\"       \n",
      " [9] \"mip_post_max\"          \"smip_post_max\"         \"fit_post_max\"          \"id_post_max\"          \n",
      "[13] \"slopesmip_post_max\"    \"pif_post_max\"          \"sindex_post_max\"       \"volume_post_max\"      \n",
      "[17] \"cpet_vo2peak_absolute\" \"cpet_ve\"               \"cpet_vt_peak\"          \"cpet_o2pulse\"         \n",
      "[21] \"fmd_percent\"          \n"
     ]
    }
   ],
   "source": [
    "# Vector of respiratory and related variables to center\n",
    "resp_vars <- c(\n",
    "  \"mip_pre_max\", \"smip_pre_max\", \"fit_pre_max\", \"id_pre_max\", \"slopesmip_pre_max\",\n",
    "  \"sindex_pre_max\", \"pif_pre_max\", \"volume_pre_max\",\n",
    "  \"mip_post_max\", \"smip_post_max\", \"fit_post_max\", \"id_post_max\", \"slopesmip_post_max\",\n",
    "  \"pif_post_max\", \"sindex_post_max\", \"volume_post_max\",\n",
    "  \"cpet_vo2peak_absolute\", \"cpet_ve\", \"cpet_vt_peak\", \"cpet_o2pulse\",\n",
    "  \"fmd_percent\"\n",
    ")\n",
    "\n",
    "# Center each variable in-place: x_centered = x - mean(x, na.rm = TRUE)\n",
    "for (v in resp_vars) {\n",
    "  if (!v %in% names(df_long)) {\n",
    "    warning(\"Variable \", v, \" not found in df_long, skipping.\")\n",
    "  } else {\n",
    "    m <- mean(df_long[[v]], na.rm = TRUE)\n",
    "    df_long[[v]] <- df_long[[v]] - m\n",
    "  }\n",
    "}\n",
    "\n",
    "cat(\"✅ Centering complete for variables:\\n\")\n",
    "print(resp_vars)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee804888",
   "metadata": {},
   "source": [
    "# Descriptives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20172953",
   "metadata": {},
   "source": [
    "# Bivariate Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "684866dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were 50 or more warnings (use warnings() to see the first 50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMBINED VISITS (1+2) - Correlations with FSS (Fatigue):\n",
      "# A tibble: 33 × 10\n",
      "# Groups:   data_source, outcome [1]\n",
      "   data_source     outcome respiratory    pearson_r pearson_p spearman_rho spearman_p     n pearson_sig\n",
      "   <chr>           <chr>   <chr>              <dbl>     <dbl>        <dbl>      <dbl> <int> <chr>      \n",
      " 1 combined_visits fss_sum mip_post_max_…    -0.615 0.0000237       -0.605  0.0000352    40 ***        \n",
      " 2 combined_visits fss_sum mip_post_max_…    -0.562 0.000160        -0.601  0.0000415    40 ***        \n",
      " 3 combined_visits fss_sum mip_post_max_…    -0.562 0.000160        -0.601  0.0000415    40 ***        \n",
      " 4 combined_visits fss_sum sindex_post_m…    -0.579 0.000112        -0.594  0.0000662    39 ***        \n",
      " 5 combined_visits fss_sum mip_post_max_…    -0.571 0.000119        -0.588  0.0000672    40 ***        \n",
      " 6 combined_visits fss_sum mip_post_max      -0.493 0.00122         -0.582  0.0000806    40 **         \n",
      " 7 combined_visits fss_sum mip_post_max_…    -0.600 0.0000424       -0.573  0.000110     40 ***        \n",
      " 8 combined_visits fss_sum mip_pre_max_p…    -0.582 0.0000811       -0.543  0.000294     40 ***        \n",
      " 9 combined_visits fss_sum cpet_vo2peak_…    -0.379 0.0208          -0.542  0.000530     37 *          \n",
      "10 combined_visits fss_sum mip_pre_max_p…    -0.596 0.0000493       -0.531  0.000424     40 ***        \n",
      "11 combined_visits fss_sum mip_pre_max_p…    -0.541 0.000316        -0.523  0.000535     40 ***        \n",
      "12 combined_visits fss_sum mip_pre_max_p…    -0.541 0.000316        -0.523  0.000535     40 ***        \n",
      "13 combined_visits fss_sum cpet_ve           -0.410 0.0177          -0.519  0.00195      33 *          \n",
      "14 combined_visits fss_sum mip_pre_max_p…    -0.545 0.000272        -0.499  0.00106      40 ***        \n",
      "15 combined_visits fss_sum sindex_pre_ma…    -0.528 0.000554        -0.493  0.00144      39 ***        \n",
      "16 combined_visits fss_sum mip_pre_max       -0.474 0.00202         -0.484  0.00154      40 **         \n",
      "17 combined_visits fss_sum sindex_post_m…    -0.426 0.00686         -0.479  0.00202      39 **         \n",
      "18 combined_visits fss_sum pif_post_max      -0.421 0.00759         -0.459  0.00328      39 **         \n",
      "19 combined_visits fss_sum smip_post_max     -0.348 0.0277          -0.388  0.0133       40 *          \n",
      "20 combined_visits fss_sum pif_pre_max       -0.389 0.0145          -0.351  0.0284       39 *          \n",
      "# ℹ 13 more rows\n",
      "# ℹ 1 more variable: spearman_sig <chr>\n",
      "# ℹ Use `print(n = ...)` to see more rows\n",
      "\n",
      "COMBINED VISITS (1+2) - Correlations with Woods MFI (Brain Fog):\n",
      "# A tibble: 0 × 10\n",
      "# Groups:   data_source, outcome [0]\n",
      "# ℹ 10 variables: data_source <chr>, outcome <chr>, respiratory <chr>, pearson_r <dbl>,\n",
      "#   pearson_p <dbl>, spearman_rho <dbl>, spearman_p <dbl>, n <int>, pearson_sig <chr>,\n",
      "#   spearman_sig <chr>\n",
      "\n",
      "VISIT 1 ONLY - Correlations with FSS (Fatigue):\n",
      "# A tibble: 33 × 10\n",
      "# Groups:   data_source, outcome [1]\n",
      "   data_source outcome respiratory        pearson_r pearson_p spearman_rho spearman_p     n pearson_sig\n",
      "   <chr>       <chr>   <chr>                  <dbl>     <dbl>        <dbl>      <dbl> <int> <chr>      \n",
      " 1 visit1_only fss_sum cpet_vo2peak_abso…    -0.530   0.0161        -0.621    0.00348    20 \"*\"        \n",
      " 2 visit1_only fss_sum sindex_post_max_p…    -0.571   0.00547       -0.600    0.00319    22 \"**\"       \n",
      " 3 visit1_only fss_sum cpet_ve               -0.511   0.0212        -0.565    0.00941    20 \"*\"        \n",
      " 4 visit1_only fss_sum mip_post_max_perc…    -0.540   0.00946       -0.523    0.0125     22 \"**\"       \n",
      " 5 visit1_only fss_sum mip_post_max_perc…    -0.479   0.0240        -0.491    0.0203     22 \"*\"        \n",
      " 6 visit1_only fss_sum mip_post_max_perc…    -0.479   0.0240        -0.491    0.0203     22 \"*\"        \n",
      " 7 visit1_only fss_sum sindex_post_max       -0.459   0.0318        -0.491    0.0203     22 \"*\"        \n",
      " 8 visit1_only fss_sum mip_post_max          -0.487   0.0217        -0.484    0.0223     22 \"*\"        \n",
      " 9 visit1_only fss_sum mip_post_max_perc…    -0.517   0.0138        -0.456    0.0327     22 \"*\"        \n",
      "10 visit1_only fss_sum pif_post_max          -0.435   0.0431        -0.455    0.0332     22 \"*\"        \n",
      "11 visit1_only fss_sum mip_post_max_perc…    -0.453   0.0344        -0.451    0.0350     22 \"*\"        \n",
      "12 visit1_only fss_sum sindex_pre_max_pe…    -0.414   0.0557        -0.343    0.118      22 \"\"         \n",
      "13 visit1_only fss_sum fmd_percent            0.231   0.328          0.326    0.160      20 \"\"         \n",
      "14 visit1_only fss_sum fit_post_max          -0.316   0.152         -0.285    0.198      22 \"\"         \n",
      "15 visit1_only fss_sum smip_post_max         -0.271   0.222         -0.267    0.229      22 \"\"         \n",
      "16 visit1_only fss_sum mip_pre_max_perce…    -0.252   0.257         -0.266    0.232      22 \"\"         \n",
      "17 visit1_only fss_sum mip_pre_max_perce…    -0.299   0.177         -0.260    0.243      22 \"\"         \n",
      "18 visit1_only fss_sum cpet_o2pulse          -0.230   0.330         -0.255    0.278      20 \"\"         \n",
      "19 visit1_only fss_sum volume_post_max        0.208   0.353          0.230    0.303      22 \"\"         \n",
      "20 visit1_only fss_sum pif_pre_max           -0.255   0.253         -0.222    0.321      22 \"\"         \n",
      "# ℹ 13 more rows\n",
      "# ℹ 1 more variable: spearman_sig <chr>\n",
      "# ℹ Use `print(n = ...)` to see more rows\n",
      "\n",
      "VISIT 1 ONLY - Correlations with Woods MFI (Brain Fog):\n",
      "# A tibble: 0 × 10\n",
      "# Groups:   data_source, outcome [0]\n",
      "# ℹ 10 variables: data_source <chr>, outcome <chr>, respiratory <chr>, pearson_r <dbl>,\n",
      "#   pearson_p <dbl>, spearman_rho <dbl>, spearman_p <dbl>, n <int>, pearson_sig <chr>,\n",
      "#   spearman_sig <chr>\n",
      "\n",
      "Wide Format Comparison (first 10 rows):\n",
      "# A tibble: 10 × 8\n",
      "   outcome respiratory       visit1_only_pearson_r combined_visits_pearson_r visit1_only_spearman_rho\n",
      "   <chr>   <chr>                             <dbl>                     <dbl>                    <dbl>\n",
      " 1 fss_sum mip_pre_max                     -0.216                    -0.474                   -0.213 \n",
      " 2 fss_sum smip_pre_max                    -0.177                    -0.261                   -0.137 \n",
      " 3 fss_sum fit_pre_max                     -0.311                    -0.124                   -0.176 \n",
      " 4 fss_sum id_pre_max                      -0.102                     0.0109                  -0.111 \n",
      " 5 fss_sum slopesmip_pre_max               -0.179                    -0.248                   -0.0517\n",
      " 6 fss_sum sindex_pre_max                  -0.263                    -0.381                   -0.218 \n",
      " 7 fss_sum pif_pre_max                     -0.255                    -0.389                   -0.222 \n",
      " 8 fss_sum volume_pre_max                   0.0885                    0.193                    0.0844\n",
      " 9 fss_sum mip_post_max                    -0.487                    -0.493                   -0.484 \n",
      "10 fss_sum smip_post_max                   -0.271                    -0.348                   -0.267 \n",
      "# ℹ 3 more variables: combined_visits_spearman_rho <dbl>, visit1_only_n <int>, combined_visits_n <int>\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate both Pearson and Spearman correlations\n",
    "calculate_correlations <- function(data, outcome, respiratory, data_source) {\n",
    "  # Remove rows with missing values for these two variables\n",
    "  clean_data <- data[complete.cases(data[c(outcome, respiratory)]), ]\n",
    "  \n",
    "  # Calculate Pearson correlation\n",
    "  pearson_result <- cor.test(clean_data[[outcome]], clean_data[[respiratory]], \n",
    "                             method = \"pearson\")\n",
    "  \n",
    "  # Calculate Spearman correlation\n",
    "  spearman_result <- cor.test(clean_data[[outcome]], clean_data[[respiratory]], \n",
    "                              method = \"spearman\")\n",
    "  \n",
    "  # Return as a data frame\n",
    "  tibble(\n",
    "    data_source = data_source,\n",
    "    outcome = outcome,\n",
    "    respiratory = respiratory,\n",
    "    pearson_r = pearson_result$estimate,\n",
    "    pearson_p = pearson_result$p.value,\n",
    "    spearman_rho = spearman_result$estimate,\n",
    "    spearman_p = spearman_result$p.value,\n",
    "    n = nrow(clean_data)\n",
    "  )\n",
    "}\n",
    "\n",
    "# Initialize results list\n",
    "correlation_results <- list()\n",
    "\n",
    "# Calculate correlations for all combinations for BOTH datasets\n",
    "i <- 1\n",
    "for (y in outcomes) {\n",
    "  for (x in resp_vars) {\n",
    "    # Combined Visit 1 + Visit 2 data\n",
    "    correlation_results[[i]] <- calculate_correlations(df_long, y, x, \"combined_visits\")\n",
    "    i <- i + 1\n",
    "    \n",
    "    # Visit 1 only data\n",
    "    visit1_data <- df_long %>% filter(time_point == 1)\n",
    "    correlation_results[[i]] <- calculate_correlations(visit1_data, y, x, \"visit1_only\")\n",
    "    i <- i + 1\n",
    "  }\n",
    "}\n",
    "\n",
    "# Combine all results\n",
    "final_correlations <- bind_rows(correlation_results)\n",
    "\n",
    "# Reorder columns to match your requested format\n",
    "final_correlations <- final_correlations %>%\n",
    "  dplyr::select(data_source, outcome, respiratory, pearson_r, pearson_p, spearman_rho, spearman_p, n)\n",
    "\n",
    "# Print a sample to check\n",
    "head(final_correlations)\n",
    "\n",
    "# Save to CSV\n",
    "write.csv(final_correlations, \"bivariate_correlations_all_data.csv\", row.names = FALSE)\n",
    "\n",
    "# Create formatted summary tables sorted by strongest Spearman correlation\n",
    "summary_correlations <- final_correlations %>%\n",
    "  group_by(data_source, outcome) %>%\n",
    "  arrange(data_source, outcome, desc(abs(spearman_rho))) %>%\n",
    "  mutate(\n",
    "    pearson_sig = case_when(\n",
    "      pearson_p < 0.001 ~ \"***\",\n",
    "      pearson_p < 0.01 ~ \"**\",\n",
    "      pearson_p < 0.05 ~ \"*\",\n",
    "      TRUE ~ \"\"\n",
    "    ),\n",
    "    spearman_sig = case_when(\n",
    "      spearman_p < 0.001 ~ \"***\",\n",
    "      spearman_p < 0.01 ~ \"**\",\n",
    "      spearman_p < 0.05 ~ \"*\",\n",
    "      TRUE ~ \"\"\n",
    "    )\n",
    "  )\n",
    "\n",
    "# Print summary tables for easy viewing\n",
    "cat(\"COMBINED VISITS (1+2) - Correlations with FSS (Fatigue):\\n\")\n",
    "summary_correlations %>% \n",
    "  filter(data_source == \"combined_visits\" & outcome == \"fss_sum\") %>% \n",
    "  print(n = 20)\n",
    "\n",
    "cat(\"\\nCOMBINED VISITS (1+2) - Correlations with Woods MFI (Brain Fog):\\n\")\n",
    "summary_correlations %>% \n",
    "  filter(data_source == \"combined_visits\" & outcome == \"woods_sum\") %>% \n",
    "  print(n = 20)\n",
    "\n",
    "cat(\"\\nVISIT 1 ONLY - Correlations with FSS (Fatigue):\\n\")\n",
    "summary_correlations %>% \n",
    "  filter(data_source == \"visit1_only\" & outcome == \"fss_sum\") %>% \n",
    "  print(n = 20)\n",
    "\n",
    "cat(\"\\nVISIT 1 ONLY - Correlations with Woods MFI (Brain Fog):\\n\")\n",
    "summary_correlations %>% \n",
    "  filter(data_source == \"visit1_only\" & outcome == \"woods_sum\") %>% \n",
    "  print(n = 20)\n",
    "\n",
    "# Save the sorted summary\n",
    "write.csv(summary_correlations, \"sorted_correlations_summary_all_data.csv\", row.names = FALSE)\n",
    "\n",
    "# Optional: Create a wide format for easy comparison between datasets\n",
    "wide_format <- final_correlations %>%\n",
    "  dplyr::select(-pearson_p, -spearman_p) %>%\n",
    "  pivot_wider(\n",
    "    names_from = data_source,\n",
    "    values_from = c(pearson_r, spearman_rho, n),\n",
    "    names_glue = \"{data_source}_{.value}\"\n",
    "  ) %>%\n",
    "  dplyr::select(outcome, respiratory, \n",
    "         visit1_only_pearson_r, combined_visits_pearson_r,\n",
    "         visit1_only_spearman_rho, combined_visits_spearman_rho,\n",
    "         visit1_only_n, combined_visits_n)\n",
    "\n",
    "# Save wide format for easy comparison\n",
    "write.csv(wide_format, \"correlations_wide_format_comparison.csv\", row.names = FALSE)\n",
    "\n",
    "cat(\"\\nWide Format Comparison (first 10 rows):\\n\")\n",
    "print(head(wide_format, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ecdd37",
   "metadata": {},
   "source": [
    "# OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47591b7f",
   "metadata": {},
   "source": [
    "## Covariate List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b101e0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning messages:\n",
      "1: In plot.new() :\n",
      "  Cannot open temporary file 'C:\\Users\\ZCooper\\AppData\\Local\\Temp\\Rtmp0cXP4B\\pdf988c1d0b2ac0' for compression (reason: No such file or directory); compression has been turned off for this device\n",
      "2: In model.matrix.default(mt, mf, contrasts) :\n",
      "  the response appeared on the right-hand side and was dropped\n",
      "3: In model.matrix.default(mt, mf, contrasts) :\n",
      "  problem with term 1 in model.matrix: no columns are assigned\n",
      "4: In model.matrix.default(object, data = list(bdi_sum = c(7, 7, 4,  :\n",
      "  the response appeared on the right-hand side and was dropped\n",
      "5: In model.matrix.default(object, data = list(bdi_sum = c(7, 7, 4,  :\n",
      "  problem with term 1 in model.matrix: no columns are assigned\n",
      "6: In model.matrix.default(object, data = list(bdi_sum = c(7, 7, 4,  :\n",
      "  the response appeared on the right-hand side and was dropped\n",
      "7: In model.matrix.default(object, data = list(bdi_sum = c(7, 7, 4,  :\n",
      "  problem with term 1 in model.matrix: no columns are assigned\n",
      "8: In model.matrix.default(object, data = list(bdi_sum = c(7, 7, 4,  :\n",
      "  the response appeared on the right-hand side and was dropped\n",
      "9: In model.matrix.default(object, data = list(bdi_sum = c(7, 7, 4,  :\n",
      "  problem with term 1 in model.matrix: no columns are assigned\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ DONE!\n",
      "• Visit 1 regression models completed\n",
      "• Covariates used: data_age, data_kilograms, data_centimeters, subject_female \n",
      "• Diagnostics PDF saved as: correlations_diagnostic_check.pdf\n",
      "• Results table saved as: visit1_regression_results.csv\n"
     ]
    }
   ],
   "source": [
    "library(dplyr)\n",
    "library(broom)\n",
    "library(ggplot2)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# CONFIGURATION - Easily modify these\n",
    "# --------------------------------------------------\n",
    "covariates <- c('data_age', 'data_kilograms', 'data_centimeters', 'subject_female')\n",
    "# Alternative examples:\n",
    "# covariates <- c('data_age')\n",
    "# covariates <- c('data_age', 'subject_female', 'education_years')\n",
    "# covariates <- character()  # for no covariates\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Filter to Visit 1 only\n",
    "# --------------------------------------------------\n",
    "df_v1 <- df_long %>%\n",
    "  filter(time_point == 1)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Storage object for regression results\n",
    "# --------------------------------------------------\n",
    "results <- list()\n",
    "idx <- 1\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Create diagnostics PDF\n",
    "# --------------------------------------------------\n",
    "pdf(\"correlations_diagnostic_check.pdf\", width = 8, height = 10)\n",
    "\n",
    "for (y in outcomes) {\n",
    "  for (x in resp_vars) {\n",
    "    \n",
    "    # Build formula dynamically based on covariates\n",
    "    if (length(covariates) > 0) {\n",
    "      formula_str <- paste(y, \"~\", x, \"+\", paste(covariates, collapse = \" + \"))\n",
    "    } else {\n",
    "      formula_str <- paste(y, \"~\", x)\n",
    "    }\n",
    "    formula <- as.formula(formula_str)\n",
    "    \n",
    "    # Select variables dynamically\n",
    "    model_vars <- c(y, x)\n",
    "    if (length(covariates) > 0) {\n",
    "      model_vars <- c(model_vars, covariates)\n",
    "    }\n",
    "    \n",
    "    # Remove missing data\n",
    "    df_model <- df_v1 %>%\n",
    "      dplyr::select(all_of(model_vars)) %>%\n",
    "      na.omit()\n",
    "    \n",
    "    # Skip if insufficient data\n",
    "    if (nrow(df_model) < 10) next\n",
    "    \n",
    "    # Fit model\n",
    "    fit <- lm(formula, data = df_model)\n",
    "    \n",
    "    # Extract regression summary\n",
    "    tidy_fit <- tidy(fit)\n",
    "    r2 <- summary(fit)$adj.r.squared\n",
    "    \n",
    "    # Store results\n",
    "    results[[idx]] <- data.frame(\n",
    "      outcome = y,\n",
    "      predictor = x,\n",
    "      beta = tidy_fit$estimate[2],\n",
    "      std_error = tidy_fit$std.error[2],\n",
    "      p_value = tidy_fit$p.value[2],\n",
    "      adj_r2 = r2,\n",
    "      N = nrow(df_model),\n",
    "      covariates_used = paste(covariates, collapse = \", \")\n",
    "    )\n",
    "    idx <- idx + 1\n",
    "    \n",
    "    # --------------------------------------------------\n",
    "    # Diagnostics plots for this model\n",
    "    # --------------------------------------------------\n",
    "    par(mfrow=c(3,1))\n",
    "    \n",
    "    plot(fit, which = 1, main = paste(\"Residuals vs Fitted:\", y, \"~\", x))\n",
    "    plot(fit, which = 2, main = paste(\"Normal Q-Q:\", y, \"~\", x))\n",
    "    plot(fit, which = 3, main = paste(\"Scale-Location:\", y, \"~\", x))\n",
    "    \n",
    "  }\n",
    "}\n",
    "\n",
    "dev.off()\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Combine and save regression table\n",
    "# --------------------------------------------------\n",
    "results_df <- bind_rows(results)\n",
    "write.csv(results_df, \"visit1_regression_results.csv\", row.names = FALSE)\n",
    "\n",
    "cat(\"\\n✅ DONE!\\n\")\n",
    "cat(\"• Visit 1 regression models completed\\n\")\n",
    "cat(\"• Covariates used:\", paste(covariates, collapse = \", \"), \"\\n\")\n",
    "cat(\"• Diagnostics PDF saved as: correlations_diagnostic_check.pdf\\n\")\n",
    "cat(\"• Results table saved as: visit1_regression_results.csv\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c222ad",
   "metadata": {},
   "source": [
    "## OG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d32016c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "In plot.new() :\n",
      "  Cannot open temporary file 'C:\\Users\\ZCooper\\AppData\\Local\\Temp\\RtmpSkdRJm\\pdf303c1a968e9' for compression (reason: No such file or directory); compression has been turned off for this device\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ DONE!\n",
      "• Visit 1 regression models completed\n",
      "• Diagnostics PDF saved as: correlations_diagnostic_check.pdf\n",
      "• Results table saved as: visit1_regression_results.csv\n"
     ]
    }
   ],
   "source": [
    "library(dplyr)\n",
    "library(broom)\n",
    "library(ggplot2)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Filter to Visit 1 only\n",
    "# --------------------------------------------------\n",
    "df_v1 <- df_long %>%\n",
    "  filter(time_point == 1)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Storage object for regression results\n",
    "# --------------------------------------------------\n",
    "results <- list()\n",
    "idx <- 1\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Create diagnostics PDF\n",
    "# --------------------------------------------------\n",
    "pdf(\"correlations_diagnostic_check.pdf\", width = 8, height = 10)\n",
    "\n",
    "for (y in outcomes) {\n",
    "  for (x in resp_vars) {\n",
    "    \n",
    "    # Build formula: outcome ~ respiratory + covariates\n",
    "    formula <- as.formula(\n",
    "      paste(y, \"~\", x, \"+ data_age + subject_female\")\n",
    "    )\n",
    "    \n",
    "    # Remove missing data\n",
    "    df_model <- df_v1 %>%\n",
    "      dplyr::select(all_of(c(y, x, \"data_age\", \"subject_female\"))) %>%\n",
    "      na.omit()\n",
    "    \n",
    "    # Skip if insufficient data\n",
    "    if (nrow(df_model) < 10) next\n",
    "    \n",
    "    # Fit model\n",
    "    fit <- lm(formula, data = df_model)\n",
    "    \n",
    "    # Extract regression summary\n",
    "    tidy_fit <- tidy(fit)\n",
    "    r2 <- summary(fit)$adj.r.squared\n",
    "    \n",
    "    # Store results\n",
    "    results[[idx]] <- data.frame(\n",
    "      outcome = y,\n",
    "      predictor = x,\n",
    "      beta = tidy_fit$estimate[2],\n",
    "      std_error = tidy_fit$std.error[2],\n",
    "      p_value = tidy_fit$p.value[2],\n",
    "      adj_r2 = r2,\n",
    "      N = nrow(df_model)\n",
    "    )\n",
    "    idx <- idx + 1\n",
    "    \n",
    "    # --------------------------------------------------\n",
    "    # Diagnostics plots for this model\n",
    "    # --------------------------------------------------\n",
    "    par(mfrow=c(3,1))\n",
    "    \n",
    "    plot(fit, which = 1, main = paste(\"Residuals vs Fitted:\", y, \"~\", x))\n",
    "    plot(fit, which = 2, main = paste(\"Normal Q-Q:\", y, \"~\", x))\n",
    "    plot(fit, which = 3, main = paste(\"Scale-Location:\", y, \"~\", x))\n",
    "    \n",
    "  }\n",
    "}\n",
    "\n",
    "dev.off()\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Combine and save regression table\n",
    "# --------------------------------------------------\n",
    "results_df <- bind_rows(results)\n",
    "write.csv(results_df, \"visit1_regression_results.csv\", row.names = FALSE)\n",
    "\n",
    "cat(\"\\n✅ DONE!\\n\")\n",
    "cat(\"• Visit 1 regression models completed\\n\")\n",
    "cat(\"• Diagnostics PDF saved as: correlations_diagnostic_check.pdf\\n\")\n",
    "cat(\"• Results table saved as: visit1_regression_results.csv\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4f1084",
   "metadata": {},
   "source": [
    "# Mean Variance Relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b6f3ed",
   "metadata": {},
   "source": [
    "## 5:09pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb468a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "library(dplyr)\n",
    "library(gridExtra)\n",
    "\n",
    "create_glm_diagnostic_plots <- function(data, outcome) {\n",
    "\n",
    "  df <- data %>% dplyr::select(all_of(outcome)) %>% rename(value = all_of(outcome))\n",
    "  df <- df %>% filter(!is.na(value))\n",
    "\n",
    "  if (nrow(df) == 0) {\n",
    "    p1 <- ggplot() + annotate(\"text\", x=0.5, y=0.5, label=\"No data\") +\n",
    "      theme_void()\n",
    "    p2 <- p1\n",
    "    return(list(plots=list(p1, p2), rec=NULL))\n",
    "  }\n",
    "\n",
    "  # ---- Distribution Plot ----\n",
    "  p1 <- ggplot(df, aes(value)) +\n",
    "    geom_histogram(aes(y=after_stat(density)), bins=30, fill=\"steelblue\", color=\"black\", alpha=.7) +\n",
    "    geom_density(fill=\"red\", alpha=.4, color=NA) +\n",
    "    geom_vline(xintercept=0, linetype=\"dashed\", color=\"darkred\", linewidth=1) +\n",
    "    labs(title=paste(\"Distribution of\", outcome), x=\"Value\", y=\"Density\") +\n",
    "    theme_minimal()\n",
    "\n",
    "  pct_zeros <- mean(df$value == 0) * 100\n",
    "  mean_val <- mean(df$value)\n",
    "  var_val <- var(df$value)\n",
    "  var_mean_ratio <- ifelse(mean_val > 0, var_val / mean_val, Inf)\n",
    "\n",
    "  stats_text <- sprintf(\"Zeros: %.1f%%\\nMean: %.2f\\nVar: %.2f\\nVar/Mean: %.2f\",\n",
    "                        pct_zeros, mean_val, var_val, var_mean_ratio)\n",
    "\n",
    "  p1 <- p1 + annotate(\"text\", x = -Inf, y = Inf, label = stats_text, \n",
    "                      hjust = -0.1, vjust = 1.2, size = 3)\n",
    "\n",
    "  # ---- Mean-Variance Plot ----\n",
    "  if (n_distinct(df$value) > 10) {\n",
    "    df_bins <- df %>% mutate(bin = ntile(value, 10)) %>%\n",
    "      group_by(bin) %>% summarise(mean = mean(value), var = var(value)) %>%\n",
    "      filter(var > 0)\n",
    "\n",
    "    if (nrow(df_bins) > 1) {\n",
    "      p2 <- ggplot(df_bins, aes(mean, var)) +\n",
    "        geom_point(size=3, color=\"darkgreen\") +\n",
    "        geom_line(aes(y = mean), color=\"red\", linetype=\"dashed\") +\n",
    "        geom_line(aes(y = mean^2), color=\"blue\", linetype=\"dashed\") +\n",
    "        labs(title=\"Mean-Variance Relationship\", x=\"Mean\", y=\"Variance\") +\n",
    "        theme_minimal()\n",
    "    } else {\n",
    "      p2 <- ggplot() + \n",
    "        annotate(\"text\", x=0.5, y=0.5, label=\"Insufficient variation\") +\n",
    "        theme_void()\n",
    "    }\n",
    "\n",
    "  } else {\n",
    "    p2 <- ggplot() + \n",
    "      annotate(\"text\", x=0.5, y=0.5, label=\"Too few unique values\") +\n",
    "      theme_void()\n",
    "  }\n",
    "\n",
    "  # --- Recommendation ---\n",
    "  rec <- generate_glm_recommendations(df$value, pct_zeros, var_mean_ratio)\n",
    "\n",
    "  list(plots=list(p1, p2), rec=rec)\n",
    "}\n",
    "\n",
    "generate_glm_recommendations <- function(x, pct_zeros, var_mean_ratio) {\n",
    "\n",
    "  unique_vals <- n_distinct(x)\n",
    "  is_count <- all(x >= 0 & x == floor(x))\n",
    "  is_binary <- unique_vals <= 2\n",
    "\n",
    "  out <- c()\n",
    "\n",
    "  if (is_binary) {\n",
    "    out <- c(out, \"PRIMARY: Logistic Regression (binary outcome)\")\n",
    "  } else if (is_count & pct_zeros > 20) {\n",
    "    if (var_mean_ratio > 2) {\n",
    "      out <- c(out, \"PRIMARY: Zero-Inflated Negative Binomial\")\n",
    "    } else {\n",
    "      out <- c(out, \"PRIMARY: Zero-Inflated Poisson\")\n",
    "    }\n",
    "  } else if (is_count) {\n",
    "    if (var_mean_ratio > 2) {\n",
    "      out <- c(out, \"PRIMARY: Negative Binomial\")\n",
    "    } else if (var_mean_ratio >= .8 & var_mean_ratio <= 1.5) {\n",
    "      out <- c(out, \"PRIMARY: Poisson Regression\")\n",
    "    } else {\n",
    "      out <- c(out, \"PRIMARY: Quasi-Poisson or Negative Binomial\")\n",
    "    }\n",
    "  } else {\n",
    "    if (pct_zeros > 30) {\n",
    "      out <- c(out, \"PRIMARY: Two-part or Hurdle model\")\n",
    "    } else {\n",
    "      out <- c(out, \"PRIMARY: Gaussian or Gamma GLM\")\n",
    "    }\n",
    "  }\n",
    "\n",
    "  if (var_mean_ratio > 5) out <- c(out, \"SECONDARY: Strong overdispersion\")\n",
    "  if (pct_zeros > 50) out <- c(out, \"SECONDARY: Zero inflation likely\")\n",
    "\n",
    "  out\n",
    "}\n",
    "\n",
    "generate_glm_selection_pdf <- function(outcomes, data, pdf_filename = \"glm_selection.pdf\") {\n",
    "\n",
    "  pdf(pdf_filename, width=8.5, height=11)  # <-- fixes sizing and removes second PDF bug\n",
    "\n",
    "  # Cover Page\n",
    "  grid.newpage()\n",
    "  grid.text(\"GLM Model Selection Report\", gp=gpar(fontsize=24, fontface=\"bold\"), y=.8)\n",
    "  grid.text(paste(\"Generated:\", Sys.Date()), gp=gpar(fontsize=14), y=.7)\n",
    "  grid.text(paste(\"Variables analyzed:\", length(outcomes)), gp=gpar(fontsize=14), y=.6)\n",
    "\n",
    "  for (outcome in outcomes) {\n",
    "\n",
    "    grid.newpage()\n",
    "    result <- create_glm_diagnostic_plots(data, outcome)\n",
    "\n",
    "    grid.arrange(result$plots[[1]], result$plots[[2]], ncol=1)\n",
    "\n",
    "    # Recommendation Page\n",
    "    grid.newpage()\n",
    "    grid.text(paste(\"GLM Recommendations for:\", outcome), \n",
    "              gp=gpar(fontsize=18, fontface=\"bold\"), y=.9)\n",
    "\n",
    "    if (length(result$rec) == 0) {\n",
    "      grid.text(\"No recommendations generated\", y=.7)\n",
    "    } else {\n",
    "      y <- .8\n",
    "      for (r in result$rec) {\n",
    "        grid.text(r, y=y, x=.1, just=\"left\", gp=gpar(fontsize=12))\n",
    "        y <- y - .05\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\n",
    "  dev.off()\n",
    "\n",
    "  return(pdf_filename)\n",
    "}\n",
    "\n",
    "results <- generate_glm_selection_pdf(\n",
    "  outcomes = outcomes,\n",
    "  data = df_long\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b946a35a",
   "metadata": {},
   "source": [
    "## OG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f9865ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were 50 or more warnings (use warnings() to see the first 50)\n"
     ]
    }
   ],
   "source": [
    "library(ggplot2)\n",
    "library(dplyr)\n",
    "library(tidyr)\n",
    "library(purrr)\n",
    "library(gridExtra)\n",
    "library(grid)\n",
    "library(scales)\n",
    "\n",
    "#------------------------------------------\n",
    "# Generate GLM Recommendation (R Version)\n",
    "#------------------------------------------\n",
    "generate_glm_recommendation <- function(data) {\n",
    "  pct_zeros <- mean(data == 0) * 100\n",
    "  mean_val <- mean(data)\n",
    "  var_val <- var(data)\n",
    "  var_mean_ratio <- ifelse(mean_val > 0, var_val / mean_val, Inf)\n",
    "  unique_vals <- dplyr::n_distinct(data)\n",
    "  \n",
    "  is_count <- all(data >= 0 & data == floor(data))\n",
    "  is_binary <- unique_vals <= 2\n",
    "  \n",
    "  recommendations <- c()\n",
    "  \n",
    "  if (is_binary) {\n",
    "    recommendations <- c(recommendations, \"PRIMARY: Logistic Regression (binary outcome)\")\n",
    "  } else if (is_count && pct_zeros > 20) {\n",
    "    if (var_mean_ratio > 2) {\n",
    "      recommendations <- c(recommendations,\n",
    "                           \"PRIMARY: Zero-Inflated Negative Binomial (excess zeros + overdispersion)\")\n",
    "    } else {\n",
    "      recommendations <- c(recommendations,\n",
    "                           \"PRIMARY: Zero-Inflated Poisson (excess zeros)\")\n",
    "    }\n",
    "  } else if (is_count) {\n",
    "    if (var_mean_ratio > 2) {\n",
    "      recommendations <- c(recommendations,\n",
    "                           \"PRIMARY: Negative Binomial (overdispersed count data)\")\n",
    "    } else if (var_mean_ratio >= 0.8 && var_mean_ratio <= 1.5) {\n",
    "      recommendations <- c(recommendations,\n",
    "                           \"PRIMARY: Poisson Regression (variance ≈ mean)\")\n",
    "    } else {\n",
    "      recommendations <- c(recommendations,\n",
    "                           \"PRIMARY: Consider Quasi-Poisson or Negative Binomial\")\n",
    "    }\n",
    "  } else {\n",
    "    if (pct_zeros > 30) {\n",
    "      recommendations <- c(recommendations,\n",
    "                           \"PRIMARY: Two-part or Hurdle model (continuous with excess zeros)\")\n",
    "    } else {\n",
    "      recommendations <- c(recommendations,\n",
    "                           \"PRIMARY: Gaussian GLM (OLS) or Gamma GLM (if positive & right-skewed)\")\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  # Secondary recs\n",
    "  if (var_mean_ratio > 5) recommendations <- c(recommendations, \"SECONDARY: Strong overdispersion detected\")\n",
    "  if (var_mean_ratio < 0.5) recommendations <- c(recommendations, \"SECONDARY: Possible underdispersion\")\n",
    "  if (pct_zeros > 50) recommendations <- c(recommendations, \"SECONDARY: Consider zero-inflation models\")\n",
    "  \n",
    "  return(recommendations)\n",
    "}\n",
    "\n",
    "#------------------------------------------\n",
    "# Create KDE + Mean-Variance Diagnostic Plots\n",
    "#------------------------------------------\n",
    "create_diagnostic_plots <- function(df, outcome) {\n",
    "  data_vec <- df[[outcome]] %>% na.omit()\n",
    "  \n",
    "  # Distribution + KDE\n",
    "  p1 <- ggplot(df, aes_string(x = outcome)) +\n",
    "    geom_histogram(aes(y = ..density..), bins = 30, fill = \"steelblue\", alpha = 0.6, color = \"black\") +\n",
    "    geom_density(fill = \"red\", alpha = 0.3) +\n",
    "    geom_vline(xintercept = 0, color = \"darkred\", linetype = \"dashed\") +\n",
    "    labs(title = paste(\"Distribution of\", outcome), y = \"Density\", x = \"Value\")\n",
    "  \n",
    "  # Mean-Variance Plot\n",
    "  if (dplyr::n_distinct(data_vec) > 10) {\n",
    "    temp <- df %>%\n",
    "      mutate(bin = ntile(.data[[outcome]], 10)) %>%\n",
    "      group_by(bin) %>%\n",
    "      summarize(mean = mean(.data[[outcome]], na.rm = TRUE),\n",
    "                var = var(.data[[outcome]], na.rm = TRUE)) %>%\n",
    "      drop_na()\n",
    "    \n",
    "    p2 <- ggplot(temp, aes(x = mean, y = var)) +\n",
    "      geom_point(size = 3, color = \"darkgreen\") +\n",
    "      geom_line(aes(y = mean), color = \"red\", linetype = \"dashed\") +\n",
    "      geom_line(aes(y = mean^2), color = \"blue\", linetype = \"dashed\") +\n",
    "      scale_x_continuous(trans = \"log10\", labels = comma) +\n",
    "      scale_y_continuous(trans = \"log10\", labels = comma) +\n",
    "      labs(title = \"Mean-Variance Relationship\", x = \"Mean\", y = \"Variance\")\n",
    "  } else {\n",
    "    p2 <- ggplot() +\n",
    "      annotate(\"text\", x = 0.5, y = 0.5,\n",
    "               label = \"Insufficient unique values for\\nmean–variance plot\", size = 6) +\n",
    "      theme_void()\n",
    "  }\n",
    "  \n",
    "  list(p1 = p1, p2 = p2)\n",
    "}\n",
    "\n",
    "#------------------------------------------\n",
    "# Create Recommendation Page (text-only)\n",
    "#------------------------------------------\n",
    "recommendation_page <- function(outcome, stats, recommendations) {\n",
    "  text <- paste(\n",
    "    sprintf(\"GLM Recommendations for: %s\\n\\n\", outcome),\n",
    "    sprintf(\"Sample size: %d\\n\", stats$n),\n",
    "    sprintf(\"Mean: %.3f\\nVariance: %.3f\\nVar/Mean ratio: %.3f\\n\", stats$mean, stats$var, stats$var_mean),\n",
    "    sprintf(\"Percentage zeros: %.1f%%\\n\", stats$pct_zeros),\n",
    "    sprintf(\"Unique values: %d\\nRange: %.2f to %.2f\\n\", stats$unique_vals, stats$min, stats$max),\n",
    "    sprintf(\"Data type: %s\\n\\n\", stats$data_type),\n",
    "    \"Model Recommendations:\\n\",\n",
    "    paste(sprintf(\"- %s\", recommendations), collapse = \"\\n\"),\n",
    "    \"\\n\\nInterpretation Guide:\\n\",\n",
    "    \"• Var/Mean ≈ 1 → Poisson OK\\n\",\n",
    "    \"• Var/Mean > 2 → Overdispersed → NegBin\\n\",\n",
    "    \"• Var/Mean < 0.8 → Underdispersed\\n\",\n",
    "    \"• High zeros → Hurdle / Zero-inflated\\n\",\n",
    "    \"• 0/1 → Logistic Regression\\n\",\n",
    "    \"• Positive continuous → Gamma GLM\\n\",\n",
    "    sep = \"\"\n",
    "  )\n",
    "  \n",
    "  grid.newpage()\n",
    "  grid.text(text, x = 0.02, y = 0.98, just = c(\"left\", \"top\"), gp = gpar(fontsize = 10))\n",
    "}\n",
    "\n",
    "#------------------------------------------\n",
    "# Main PDF Generator\n",
    "#------------------------------------------\n",
    "generate_glm_selection_pdf <- function(outcomes, data, pdf_filename = NULL) {\n",
    "  \n",
    "  if (is.null(pdf_filename)) {\n",
    "    pdf_filename <- paste0(\"glm_model_selection_\", format(Sys.time(), \"%Y%m%d_%H%M%S\"), \".pdf\")\n",
    "  }\n",
    "  \n",
    "  pdf(pdf_filename, width = 8.5, height = 11)\n",
    "  \n",
    "  # Title Page\n",
    "  grid.newpage()\n",
    "  grid.text(\"GLM Model Selection Report\", y = 0.8, gp = gpar(fontsize = 24, fontface = \"bold\"))\n",
    "  grid.text(paste(\"Generated:\", format(Sys.Date(), \"%B %d, %Y\")), y = 0.7, gp = gpar(fontsize = 14))\n",
    "  grid.text(paste(\"Variables analyzed:\", length(outcomes)), y = 0.6, gp = gpar(fontsize = 14))\n",
    "  \n",
    "  results <- list()\n",
    "  \n",
    "  for (outcome in outcomes) {\n",
    "    if (!(outcome %in% names(data))) next\n",
    "    \n",
    "    vec <- na.omit(data[[outcome]])\n",
    "    if (length(vec) == 0) next\n",
    "    \n",
    "    # Stats\n",
    "    stats <- list(\n",
    "      n = length(vec),\n",
    "      mean = mean(vec),\n",
    "      var = var(vec),\n",
    "      var_mean = ifelse(mean(vec) > 0, var(vec)/mean(vec), Inf),\n",
    "      pct_zeros = mean(vec == 0) * 100,\n",
    "      unique_vals = n_distinct(vec),\n",
    "      min = min(vec),\n",
    "      max = max(vec),\n",
    "      data_type =\n",
    "        if (n_distinct(vec) <= 2) \"Binary\"\n",
    "        else if (all(vec >= 0 & vec == floor(vec))) \"Count\"\n",
    "        else \"Continuous\"\n",
    "    )\n",
    "    \n",
    "    recs <- generate_glm_recommendation(vec)\n",
    "    results[[outcome]] <- recs\n",
    "    \n",
    "    # Plots\n",
    "    plots <- create_diagnostic_plots(data, outcome)\n",
    "    grid.arrange(plots$p1, plots$p2, ncol = 2,\n",
    "                 top = textGrob(paste(\"GLM Diagnostics:\", outcome),\n",
    "                                gp = gpar(fontsize = 16, fontface = \"bold\")))\n",
    "    \n",
    "    # Page: Recommendations\n",
    "    recommendation_page(outcome, stats, recs)\n",
    "  }\n",
    "  \n",
    "  dev.off()\n",
    "  \n",
    "  return(list(pdf = pdf_filename, recommendations = results))\n",
    "}\n",
    "\n",
    "results <- generate_glm_selection_pdf(\n",
    "  outcomes = outcomes,\n",
    "  data = df_long\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ce1765",
   "metadata": {},
   "source": [
    "# OLS Moderation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169823ea",
   "metadata": {},
   "source": [
    "## 1036"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7bd632fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ DONE!\n",
      "• NB GLMMs fit with three random structures per outcome × resp_type\n",
      "• Model comparison saved to: fatigue_glmm_model_comparison.csv\n",
      "• Interaction term results saved to: fatigue_glmm_regressionresults.csv\n"
     ]
    }
   ],
   "source": [
    "library(dplyr)\n",
    "library(tidyr)\n",
    "library(lme4)   # for glmer.nb\n",
    "\n",
    "# --------------------------------------------------\n",
    "# CONFIGURATION\n",
    "# --------------------------------------------------\n",
    "covariates    <- c()\n",
    "outcomes      <- c(\"fss_sum\", \"woods_sum\", \"dsq_sum\")\n",
    "resp_types    <- c(\"mip\", \"smip\", \"fit\", \"id\", \"slopesmip\", \"sindex\", \"pif\", \"volume\")\n",
    "condition_var <- \"condition\"   # 0 = pre, 1 = post\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Create long format dataframe for pre/post analysis\n",
    "# --------------------------------------------------\n",
    "df_prepost <- df_long %>%\n",
    "  filter(time_point %in% c(1, 2)) %>%\n",
    "  mutate(condition = ifelse(time_point == 1, 0, 1)) %>%\n",
    "  dplyr::select(\n",
    "    record_id,\n",
    "    condition,\n",
    "    all_of(outcomes),\n",
    "    matches(paste0(\"^(\", paste(resp_types, collapse = \"|\"), \")_(pre|post)_max$\")),\n",
    "    all_of(covariates)\n",
    "  ) %>%\n",
    "  pivot_longer(\n",
    "    cols = matches(paste0(\"^(\", paste(resp_types, collapse = \"|\"), \")_(pre|post)_max$\")),\n",
    "    names_to      = c(\"resp_type\", \"time\", \".value\"),\n",
    "    names_pattern = \"(.+)_(pre|post)_(.+)\"\n",
    "  ) %>%\n",
    "  rename(resp_value = max) %>%\n",
    "  filter(!is.na(resp_value)) %>%\n",
    "  distinct()\n",
    "\n",
    "# Optional sanity check:\n",
    "# df_prepost %>% count(record_id, resp_type, condition)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# GLMM model comparison: random intercept vs slope vs intercept+slope\n",
    "# --------------------------------------------------\n",
    "model_comp_list <- list()  # for fatigue_glmm_model_comparison.csv\n",
    "reg_results     <- list()  # for fatigue_glmm_regressionresults.csv\n",
    "comp_idx        <- 1\n",
    "reg_idx         <- 1\n",
    "\n",
    "for (y in outcomes) {\n",
    "  for (resp in resp_types) {\n",
    "    \n",
    "    # Subset to this respiratory measure\n",
    "    df_model <- df_prepost %>%\n",
    "      filter(resp_type == resp) %>%\n",
    "      dplyr::select(record_id, condition, resp_value, all_of(y), all_of(covariates)) %>%\n",
    "      na.omit()\n",
    "    \n",
    "    # Need reasonable data to fit a GLMM\n",
    "    if (nrow(df_model) < 10) next\n",
    "    if (length(unique(df_model[[condition_var]])) < 2) next\n",
    "    if (length(unique(df_model$record_id)) < 5) next  # simple guardrail\n",
    "    \n",
    "    # --------------------------------------------------\n",
    "    # Fixed part of the formula\n",
    "    # outcome ~ resp_value * condition + covariates\n",
    "    # --------------------------------------------------\n",
    "    if (length(covariates) > 0) {\n",
    "      fixed_rhs <- paste(\"resp_value * condition\",\n",
    "                         paste(covariates, collapse = \" + \"),\n",
    "                         sep = \" + \")\n",
    "    } else {\n",
    "      fixed_rhs <- \"resp_value * condition\"\n",
    "    }\n",
    "    \n",
    "    # Random structures\n",
    "    form_int   <- as.formula(paste(y, \"~\", fixed_rhs, \"+ (1 | record_id)\"))\n",
    "    form_slope <- as.formula(paste(y, \"~\", fixed_rhs, \"+ (0 + resp_value | record_id)\"))\n",
    "    form_both  <- as.formula(paste(y, \"~\", fixed_rhs, \"+ (1 + resp_value | record_id)\"))\n",
    "    \n",
    "    # --------------------------------------------------\n",
    "    # Fit models with error-only tryCatch\n",
    "    # (warnings will print but not crash)\n",
    "    # --------------------------------------------------\n",
    "    fit_int <- suppressWarnings(\n",
    "      tryCatch(\n",
    "        glmer.nb(\n",
    "          form_int,\n",
    "          data    = df_model,\n",
    "          control = glmerControl(optimizer = \"bobyqa\",\n",
    "                                 optCtrl   = list(maxfun = 2e5))\n",
    "        ),\n",
    "        error = function(e) {\n",
    "          message(\"Error (random intercept) for \", y, \" ~ \", resp, \": \", conditionMessage(e))\n",
    "          NULL\n",
    "        }\n",
    "      )\n",
    "    )\n",
    "    \n",
    "    fit_slope <- suppressWarnings(\n",
    "      tryCatch(\n",
    "        glmer.nb(\n",
    "          form_slope,\n",
    "          data    = df_model,\n",
    "          control = glmerControl(optimizer = \"bobyqa\",\n",
    "                                 optCtrl   = list(maxfun = 2e5))\n",
    "        ),\n",
    "        error = function(e) {\n",
    "          message(\"Error (random slope) for \", y, \" ~ \", resp, \": \", conditionMessage(e))\n",
    "          NULL\n",
    "        }\n",
    "      )\n",
    "    )\n",
    "    \n",
    "    fit_both <- suppressWarnings(\n",
    "      tryCatch(\n",
    "        glmer.nb(\n",
    "          form_both,\n",
    "          data    = df_model,\n",
    "          control = glmerControl(optimizer = \"bobyqa\",\n",
    "                                 optCtrl   = list(maxfun = 2e5))\n",
    "        ),\n",
    "        error = function(e) {\n",
    "          message(\"Error (random intercept + slope) for \", y, \" ~ \", resp, \": \", conditionMessage(e))\n",
    "          NULL\n",
    "        }\n",
    "      )\n",
    "    )\n",
    "    \n",
    "    # --------------------------------------------------\n",
    "    # Collect AICs\n",
    "    # --------------------------------------------------\n",
    "    aic_int   <- if (!is.null(fit_int))   AIC(fit_int)   else NA_real_\n",
    "    aic_slope <- if (!is.null(fit_slope)) AIC(fit_slope) else NA_real_\n",
    "    aic_both  <- if (!is.null(fit_both))  AIC(fit_both)  else NA_real_\n",
    "    \n",
    "    aic_vec <- c(\n",
    "      random_intercept  = aic_int,\n",
    "      random_slope      = aic_slope,\n",
    "      random_int_slope  = aic_both\n",
    "    )\n",
    "    \n",
    "    # If all failed, skip\n",
    "    if (all(is.na(aic_vec))) next\n",
    "    \n",
    "    # Choose best random structure\n",
    "    best_name <- names(which.min(aic_vec))\n",
    "    best_fit  <- switch(\n",
    "      best_name,\n",
    "      random_intercept = fit_int,\n",
    "      random_slope     = fit_slope,\n",
    "      random_int_slope = fit_both\n",
    "    )\n",
    "    \n",
    "    # Just in case\n",
    "    if (is.null(best_fit)) next\n",
    "    \n",
    "    # Save model comparison info\n",
    "    model_comp_list[[comp_idx]] <- data.frame(\n",
    "      outcome       = y,\n",
    "      resp_type     = resp,\n",
    "      N             = nrow(df_model),\n",
    "      n_subjects    = length(unique(df_model$record_id)),\n",
    "      covariates    = if (length(covariates) > 0) paste(covariates, collapse = \", \") else \"none\",\n",
    "      AIC_random_intercept   = aic_int,\n",
    "      AIC_random_slope       = aic_slope,\n",
    "      AIC_random_int_slope   = aic_both,\n",
    "      best_random_structure  = best_name,\n",
    "      stringsAsFactors       = FALSE\n",
    "    )\n",
    "    comp_idx <- comp_idx + 1\n",
    "    \n",
    "    # --------------------------------------------------\n",
    "    # Extract interaction term from best model\n",
    "    # --------------------------------------------------\n",
    "    coef_mat  <- summary(best_fit)$coefficients\n",
    "    term_name <- \"resp_value:condition\"  # interaction with centered resp_value\n",
    "    \n",
    "    if (term_name %in% rownames(coef_mat)) {\n",
    "      est <- coef_mat[term_name, \"Estimate\"]\n",
    "      se  <- coef_mat[term_name, \"Std. Error\"]\n",
    "      z   <- coef_mat[term_name, \"z value\"]\n",
    "      p   <- coef_mat[term_name, \"Pr(>|z|)\"]\n",
    "    } else {\n",
    "      est <- se <- z <- p <- NA_real_\n",
    "    }\n",
    "    \n",
    "    reg_results[[reg_idx]] <- data.frame(\n",
    "      outcome          = y,\n",
    "      resp_type        = resp,\n",
    "      best_random_str  = best_name,\n",
    "      N                = nrow(df_model),\n",
    "      n_subjects       = length(unique(df_model$record_id)),\n",
    "      beta_interaction = est,\n",
    "      se_interaction   = se,\n",
    "      z_interaction    = z,\n",
    "      p_interaction    = p,\n",
    "      covariates       = if (length(covariates) > 0) paste(covariates, collapse = \", \") else \"none\",\n",
    "      stringsAsFactors = FALSE\n",
    "    )\n",
    "    reg_idx <- reg_idx + 1\n",
    "  }\n",
    "}\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Save outputs as CSVs\n",
    "# --------------------------------------------------\n",
    "fatigue_glmm_model_comparison <- bind_rows(model_comp_list)\n",
    "write.csv(\n",
    "  fatigue_glmm_model_comparison,\n",
    "  \"fatigue_glmm_model_comparison.csv\",\n",
    "  row.names = FALSE\n",
    ")\n",
    "\n",
    "fatigue_glmm_regressionresults <- bind_rows(reg_results)\n",
    "write.csv(\n",
    "  fatigue_glmm_regressionresults,\n",
    "  \"fatigue_glmm_regressionresults.csv\",\n",
    "  row.names = FALSE\n",
    ")\n",
    "\n",
    "cat(\"\\n✅ DONE!\\n\")\n",
    "cat(\"• NB GLMMs fit with three random structures per outcome × resp_type\\n\")\n",
    "cat(\"• Model comparison saved to: fatigue_glmm_model_comparison.csv\\n\")\n",
    "cat(\"• Interaction term results saved to: fatigue_glmm_regressionresults.csv\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736746b1",
   "metadata": {},
   "source": [
    "## OG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3933bf0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "package ‘broom.mixed’ was built under R version 4.3.3 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`geom_smooth()` using formula = 'y ~ x'\n",
      "`geom_smooth()` using formula = 'y ~ x'\n",
      "`geom_smooth()` using formula = 'y ~ x'\n",
      "`geom_smooth()` using formula = 'y ~ x'\n",
      "`geom_smooth()` using formula = 'y ~ x'\n",
      "`geom_smooth()` using formula = 'y ~ x'\n",
      "`geom_smooth()` using formula = 'y ~ x'\n",
      "`geom_smooth()` using formula = 'y ~ x'\n",
      "`geom_smooth()` using formula = 'y ~ x'\n",
      "`geom_smooth()` using formula = 'y ~ x'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "In plot.new() :\n",
      "  Cannot open temporary file 'C:\\Users\\ZCooper\\AppData\\Local\\Temp\\Rtmp0cXP4B\\pdf988c521b946' for compression (reason: No such file or directory); compression has been turned off for this device\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 SIGNIFICANT MODERATION EFFECTS FOUND!\n",
      "    outcome predictor interaction_p interaction_beta\n",
      "1   fss_sum slopesmip   0.000459908      -0.23851623\n",
      "2   fss_sum        id   0.001594162       0.99439955\n",
      "3   dsq_sum      smip   0.007698588      -0.02006350\n",
      "4   dsq_sum       mip   0.013574379      -0.11790156\n",
      "5 woods_sum      smip   0.016345720      -0.01608678\n",
      "\n",
      "✅ MODERATION ANALYSIS COMPLETE!\n",
      "• Pre/post moderation models: 24 \n",
      "• Significant interactions: 5 \n",
      "• Results saved as: moderation_results.csv\n",
      "• Scatterplots saved as: moderation_scatterplots.pdf\n",
      "• Diagnostics saved as: moderation_diagnostics.pdf\n",
      "• Covariates used: data_age, subject_female \n"
     ]
    }
   ],
   "source": [
    "library(dplyr)\n",
    "library(broom)\n",
    "library(broom.mixed)\n",
    "library(ggplot2)\n",
    "library(lme4)\n",
    "library(lmerTest)\n",
    "library(car)\n",
    "library(purrr)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# CONFIGURATION\n",
    "# --------------------------------------------------\n",
    "covariates <- c('data_age', 'subject_female')\n",
    "outcomes <- c(\"fss_sum\", \"woods_sum\", \"dsq_sum\")\n",
    "resp_vars_base <- c(\"mip\", \"smip\", \"fit\", \"id\", \"slopesmip\", \"sindex\", \"pif\", \"volume\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Create long format dataframe for pre/post analysis\n",
    "# --------------------------------------------------\n",
    "df_prepost <- df_long %>%\n",
    "  # Filter to include both pre and post time points\n",
    "  filter(time_point %in% c(1, 2)) %>%\n",
    "  # Create condition variable: 0 = pre, 1 = post\n",
    "  mutate(condition = ifelse(time_point == 1, 0, 1)) %>%\n",
    "  # Select relevant columns\n",
    "  dplyr::select(record_id, condition, all_of(outcomes), \n",
    "                matches(paste0(\"^(\", paste(resp_vars_base, collapse = \"|\"), \")_(pre|post)_max$\")),\n",
    "                all_of(covariates)) %>%\n",
    "  # Reshape to long format for respiratory variables\n",
    "  pivot_longer(\n",
    "    cols = matches(paste0(\"^(\", paste(resp_vars_base, collapse = \"|\"), \")_(pre|post)_max$\")),\n",
    "    names_to = c(\"resp_type\", \"time\", \".value\"),\n",
    "    names_pattern = \"(.+)_(pre|post)_(.+)\"\n",
    "  ) %>%\n",
    "  rename(resp_value = max) %>%\n",
    "  filter(!is.na(resp_value)) %>%\n",
    "  # Remove duplicate rows if any\n",
    "  distinct()\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Storage for moderation results\n",
    "# --------------------------------------------------\n",
    "moderation_results <- list()\n",
    "plot_data <- list()  # Store data for significant interactions\n",
    "idx <- 1\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Create output PDFs\n",
    "# --------------------------------------------------\n",
    "pdf(\"moderation_scatterplots.pdf\", width = 10, height = 8)\n",
    "pdf(\"moderation_diagnostics.pdf\", width = 10, height = 8)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Moderation analysis loop\n",
    "# --------------------------------------------------\n",
    "for (y in outcomes) {\n",
    "  for (resp in resp_vars_base) {\n",
    "    \n",
    "    # Check if we have data for this respiratory variable\n",
    "    if (!resp %in% unique(df_prepost$resp_type)) next\n",
    "    \n",
    "    # Prepare data for this specific analysis\n",
    "    df_analysis <- df_prepost %>%\n",
    "      filter(resp_type == resp) %>%\n",
    "      dplyr::select(record_id, condition, all_of(y), resp_value, all_of(covariates)) %>%\n",
    "      rename(outcome = !!y) %>%\n",
    "      na.omit()\n",
    "    \n",
    "    # Skip if insufficient data\n",
    "    if (nrow(df_analysis) < 20 || length(unique(df_analysis$record_id)) < 10) {\n",
    "      cat(\"Skipping\", y, \"~\", resp, \"- insufficient data\\n\")\n",
    "      next\n",
    "    }\n",
    "    \n",
    "    # Build formula for mixed effects model with moderation\n",
    "    if (length(covariates) > 0) {\n",
    "      formula <- as.formula(\n",
    "        paste(\"outcome ~ resp_value * condition +\", \n",
    "              paste(covariates, collapse = \" + \"), \n",
    "              \"+ (1 | record_id)\")\n",
    "      )\n",
    "    } else {\n",
    "      formula <- as.formula(\"outcome ~ resp_value * condition + (1 | record_id)\")\n",
    "    }\n",
    "    \n",
    "    # Fit mixed effects model\n",
    "    fit <- lmer(formula, data = df_analysis)\n",
    "    \n",
    "    # Extract results\n",
    "    tidy_fit <- tidy(fit)\n",
    "    \n",
    "    # Calculate R-squared manually if MuMIn not available\n",
    "    tryCatch({\n",
    "      if (!require(MuMIn, quietly = TRUE)) {\n",
    "        # Manual R-squared calculation\n",
    "        var_fixed <- var(predict(fit, re.form = NA))\n",
    "        var_random <- var(predict(fit) - predict(fit, re.form = NA))\n",
    "        var_resid <- var(residuals(fit))\n",
    "        var_total <- var_fixed + var_random + var_resid\n",
    "        marginal_r2 <- var_fixed / var_total\n",
    "        conditional_r2 <- (var_fixed + var_random) / var_total\n",
    "        r2 <- c(marginal_r2, conditional_r2)\n",
    "      } else {\n",
    "        r2 <- MuMIn::r.squaredGLMM(fit)\n",
    "      }\n",
    "    }, error = function(e) {\n",
    "      r2 <- c(NA, NA)  # If R-squared calculation fails\n",
    "    })\n",
    "    \n",
    "    # Store moderation results\n",
    "    interaction_term <- \"resp_value:condition\"\n",
    "    interaction_row <- tidy_fit[tidy_fit$term == interaction_term, ]\n",
    "    \n",
    "    moderation_results[[idx]] <- data.frame(\n",
    "      outcome = y,\n",
    "      predictor = resp,\n",
    "      interaction_term = interaction_term,\n",
    "      interaction_beta = ifelse(nrow(interaction_row) > 0, interaction_row$estimate, NA),\n",
    "      interaction_se = ifelse(nrow(interaction_row) > 0, interaction_row$std.error, NA),\n",
    "      interaction_t = ifelse(nrow(interaction_row) > 0, interaction_row$statistic, NA),\n",
    "      interaction_p = ifelse(nrow(interaction_row) > 0, interaction_row$p.value, NA),\n",
    "      marginal_r2 = ifelse(exists(\"r2\"), r2[1], NA),\n",
    "      conditional_r2 = ifelse(exists(\"r2\"), r2[2], NA),\n",
    "      N_observations = nrow(df_analysis),\n",
    "      N_subjects = length(unique(df_analysis$record_id)),\n",
    "      covariates_used = paste(covariates, collapse = \", \")\n",
    "    )\n",
    "    \n",
    "    # --------------------------------------------------\n",
    "    # Create scatterplot for significant interactions (p < 0.05)\n",
    "    # --------------------------------------------------\n",
    "    if (nrow(interaction_row) > 0 && !is.na(interaction_row$p.value) && interaction_row$p.value < 0.05) {\n",
    "      \n",
    "      # Create scatterplot with regression lines by condition\n",
    "      p <- ggplot(df_analysis, aes(x = resp_value, y = outcome, color = factor(condition))) +\n",
    "        geom_point(alpha = 0.6) +\n",
    "        geom_smooth(method = \"lm\", se = TRUE) +\n",
    "        scale_color_manual(values = c(\"0\" = \"blue\", \"1\" = \"red\"),\n",
    "                         labels = c(\"0\" = \"Pre\", \"1\" = \"Post\"),\n",
    "                         name = \"Condition\") +\n",
    "        labs(title = paste(\"Moderation:\", y, \"~\", resp, \"× Condition\"),\n",
    "             subtitle = paste(\"Interaction p =\", round(interaction_row$p.value, 4)),\n",
    "             x = resp,\n",
    "             y = y) +\n",
    "        theme_minimal()\n",
    "      \n",
    "      print(p)\n",
    "      \n",
    "      # Also create a simple effects plot (pre vs post separately)\n",
    "      p_simple <- ggplot(df_analysis, aes(x = resp_value, y = outcome)) +\n",
    "        geom_point(alpha = 0.6) +\n",
    "        geom_smooth(method = \"lm\", se = TRUE) +\n",
    "        facet_wrap(~ condition, labeller = as_labeller(c(\"0\" = \"Pre\", \"1\" = \"Post\"))) +\n",
    "        labs(title = paste(\"Simple Effects:\", y, \"~\", resp),\n",
    "             subtitle = paste(\"Interaction p =\", round(interaction_row$p.value, 4)),\n",
    "             x = resp,\n",
    "             y = y) +\n",
    "        theme_minimal()\n",
    "      \n",
    "      print(p_simple)\n",
    "    }\n",
    "    \n",
    "    # --------------------------------------------------\n",
    "    # Diagnostic plots\n",
    "    # --------------------------------------------------\n",
    "    par(mfrow = c(2, 2))\n",
    "    \n",
    "    # 1. Q-Q plot for residuals\n",
    "    qqnorm(residuals(fit), main = paste(\"Q-Q Plot:\", y, \"~\", resp))\n",
    "    qqline(residuals(fit))\n",
    "    \n",
    "    # 2. Residuals vs Fitted\n",
    "    plot(fitted(fit), residuals(fit), \n",
    "         main = paste(\"Residuals vs Fitted:\", y, \"~\", resp),\n",
    "         xlab = \"Fitted values\", ylab = \"Residuals\")\n",
    "    abline(h = 0, col = \"red\")\n",
    "    \n",
    "    # 3. Scale-Location plot\n",
    "    plot(fitted(fit), sqrt(abs(residuals(fit))),\n",
    "         main = paste(\"Scale-Location:\", y, \"~\", resp),\n",
    "         xlab = \"Fitted values\", ylab = \"√|Standardized residuals|\")\n",
    "    \n",
    "    # 4. Check for multicollinearity (VIF for fixed effects)\n",
    "    tryCatch({\n",
    "      vif_values <- vif(fit)\n",
    "      barplot(vif_values, main = paste(\"VIF Values:\", y, \"~\", resp),\n",
    "              ylab = \"VIF\", las = 2, cex.names = 0.7)\n",
    "      abline(h = 5, col = \"red\", lty = 2)\n",
    "      abline(h = 10, col = \"red\", lty = 2)\n",
    "    }, error = function(e) {\n",
    "      plot(1, type = \"n\", axes = FALSE, xlab = \"\", ylab = \"\",\n",
    "           main = paste(\"VIF not available:\", y, \"~\", resp))\n",
    "      text(1, 1, \"VIF calculation failed\", cex = 0.8)\n",
    "    })\n",
    "    \n",
    "    idx <- idx + 1\n",
    "  }\n",
    "}\n",
    "\n",
    "dev.off()  # Close PDFs\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Save moderation results\n",
    "# --------------------------------------------------\n",
    "moderation_df <- bind_rows(moderation_results)\n",
    "write.csv(moderation_df, \"moderation_results.csv\", row.names = FALSE)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Create summary of significant interactions\n",
    "# --------------------------------------------------\n",
    "significant_interactions <- moderation_df %>%\n",
    "  filter(interaction_p < 0.05) %>%\n",
    "  arrange(interaction_p)\n",
    "\n",
    "if (nrow(significant_interactions) > 0) {\n",
    "  write.csv(significant_interactions, \"significant_moderation_effects.csv\", row.names = FALSE)\n",
    "  cat(\"\\n🎯 SIGNIFICANT MODERATION EFFECTS FOUND!\\n\")\n",
    "  print(significant_interactions[, c(\"outcome\", \"predictor\", \"interaction_p\", \"interaction_beta\")])\n",
    "} else {\n",
    "  cat(\"\\n❌ No significant moderation effects found (p < 0.05)\\n\")\n",
    "}\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Completion message\n",
    "# --------------------------------------------------\n",
    "cat(\"\\n✅ MODERATION ANALYSIS COMPLETE!\\n\")\n",
    "cat(\"• Pre/post moderation models:\", nrow(moderation_df), \"\\n\")\n",
    "cat(\"• Significant interactions:\", nrow(significant_interactions), \"\\n\")\n",
    "cat(\"• Results saved as: moderation_results.csv\\n\")\n",
    "cat(\"• Scatterplots saved as: moderation_scatterplots.pdf\\n\")\n",
    "cat(\"• Diagnostics saved as: moderation_diagnostics.pdf\\n\")\n",
    "cat(\"• Covariates used:\", paste(covariates, collapse = \", \"), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0669cb",
   "metadata": {},
   "source": [
    "# GLM Moderation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986e51cd",
   "metadata": {},
   "source": [
    "## Fixed effects model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c72eed87",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "Error in `mutate()`:\nℹ In argument: `condition = ifelse(condition == 0, 0, 1)`.\nCaused by error:\n! object 'condition' not found",
     "output_type": "error",
     "traceback": [
      "Error in `mutate()`:\n",
      "ℹ In argument: `condition = ifelse(condition == 0, 0, 1)`.\n",
      "Caused by error:\n",
      "! object 'condition' not found\n",
      "     ▆\n",
      "  1. ├─... %>% distinct()\n",
      "  2. ├─dplyr::distinct(.)\n",
      "  3. ├─dplyr::filter(., !is.na(resp_value))\n",
      "  4. ├─dplyr::rename(., resp_value = max)\n",
      "  5. ├─tidyr::pivot_longer(...)\n",
      "  6. ├─dplyr::select(...)\n",
      "  7. ├─dplyr::mutate(., condition = ifelse(condition == 0, 0, 1))\n",
      "  8. ├─dplyr:::mutate.data.frame(., condition = ifelse(condition == 0, 0, 1))\n",
      "  9. │ └─dplyr:::mutate_cols(.data, dplyr_quosures(...), by)\n",
      " 10. │   ├─base::withCallingHandlers(...)\n",
      " 11. │   └─dplyr:::mutate_col(dots[[i]], data, mask, new_columns)\n",
      " 12. │     └─mask$eval_all_mutate(quo)\n",
      " 13. │       └─dplyr (local) eval()\n",
      " 14. ├─base::ifelse(condition == 0, 0, 1)\n",
      " 15. └─base::.handleSimpleError(...)\n",
      " 16.   └─dplyr (local) h(simpleError(msg, call))\n",
      " 17.     └─rlang::abort(message, class = error_class, parent = parent, call = error_call)"
     ]
    }
   ],
   "source": [
    "library(dplyr)\n",
    "library(tidyr)\n",
    "library(ggplot2)\n",
    "library(broom)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# CONFIGURATION\n",
    "# --------------------------------------------------\n",
    "covariates    <- c()\n",
    "outcomes      <- c(\"fss_sum\", \"woods_sum\", \"dsq_sum\")\n",
    "resp_types    <- c(\"mip\", \"smip\", \"fit\", \"id\", \"slopesmip\", \"sindex\", \"pif\", \"volume\")\n",
    "condition_var <- \"condition\"   # 0 = pre, 1 = post\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Create long format dataframe for pre/post analysis\n",
    "# (assumes df_long already exists and, if you wanted, \n",
    "#  respiratory variables have been centered in df_long)\n",
    "# --------------------------------------------------\n",
    "df_prepost <- df_long %>%\n",
    "  # ONLY use pre-intervention date\n",
    "  filter(time_point == 0) %>%\n",
    "  \n",
    "  # condition already encoded as 0 = pre-treadmill, 1 = post-treadmill\n",
    "  mutate(condition = ifelse(condition == 0, 0, 1)) %>%\n",
    "  \n",
    "  dplyr::select(\n",
    "    record_id,\n",
    "    condition,\n",
    "    all_of(outcomes),\n",
    "    matches(paste0(\"^(\", paste(resp_types, collapse = \"|\"), \")_(pre|post)_max$\")),\n",
    "    all_of(covariates)\n",
    "  ) %>%\n",
    "  \n",
    "  pivot_longer(\n",
    "    cols = matches(paste0(\"^(\", paste(resp_types, collapse = \"|\"), \")_(pre|post)_max$\")),\n",
    "    names_to      = c(\"resp_type\", \"time\", \".value\"),\n",
    "    names_pattern = \"(.+)_(pre|post)_(.+)\"\n",
    "  ) %>%\n",
    "  \n",
    "  rename(resp_value = max) %>%\n",
    "  filter(!is.na(resp_value)) %>%\n",
    "  distinct()\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Storage for regression results\n",
    "# --------------------------------------------------\n",
    "reg_results <- list()\n",
    "reg_idx     <- 1\n",
    "\n",
    "# --------------------------------------------------\n",
    "# PDF for diagnostics (one set of plots per model)\n",
    "# --------------------------------------------------\n",
    "pdf(\"fatigue_lm_diagnosticcheck.pdf\", width = 8, height = 10)\n",
    "\n",
    "for (y in outcomes) {\n",
    "  for (resp in resp_types) {\n",
    "    \n",
    "    # Subset to this respiratory measure\n",
    "    df_model <- df_prepost %>%\n",
    "      filter(resp_type == resp) %>%\n",
    "      dplyr::select(record_id, condition, resp_value, all_of(y), all_of(covariates)) %>%\n",
    "      na.omit()\n",
    "    \n",
    "    # Basic guards\n",
    "    if (nrow(df_model) < 10) next\n",
    "    if (length(unique(df_model[[condition_var]])) < 2) next\n",
    "    if (length(unique(df_model$record_id)) < 5) next  # still a small guard, but more lenient than GLMM\n",
    "    \n",
    "    # --------------------------------------------------\n",
    "    # Build formula: outcome ~ resp_value * condition + covariates\n",
    "    # --------------------------------------------------\n",
    "    if (length(covariates) > 0) {\n",
    "      fixed_rhs <- paste(\"resp_value * condition\",\n",
    "                         paste(covariates, collapse = \" + \"),\n",
    "                         sep = \" + \")\n",
    "    } else {\n",
    "      fixed_rhs <- \"resp_value * condition\"\n",
    "    }\n",
    "    \n",
    "    formula_str <- paste(y, \"~\", fixed_rhs)\n",
    "    form_lm     <- as.formula(formula_str)\n",
    "    \n",
    "    # --------------------------------------------------\n",
    "    # Fit linear model\n",
    "    # --------------------------------------------------\n",
    "    fit <- lm(form_lm, data = df_model)\n",
    "    \n",
    "    # --------------------------------------------------\n",
    "    # Diagnostics plots for this model\n",
    "    # --------------------------------------------------\n",
    "    par(mfrow = c(3, 1))\n",
    "    \n",
    "    # 1) Residuals vs Fitted\n",
    "    plot(\n",
    "      fit,\n",
    "      which = 1,\n",
    "      main = paste(\"Residuals vs Fitted:\", y, \"~ resp_value (\", resp, \")\")\n",
    "    )\n",
    "    \n",
    "    # 2) Normal Q-Q\n",
    "    plot(\n",
    "      fit,\n",
    "      which = 2,\n",
    "      main = paste(\"Normal Q-Q:\", y, \"~ resp_value (\", resp, \")\")\n",
    "    )\n",
    "    \n",
    "    # 3) Scale-Location\n",
    "    plot(\n",
    "      fit,\n",
    "      which = 3,\n",
    "      main = paste(\"Scale-Location:\", y, \"~ resp_value (\", resp, \")\")\n",
    "    )\n",
    "    \n",
    "    # --------------------------------------------------\n",
    "    # Extract interaction term + model info\n",
    "    # --------------------------------------------------\n",
    "    tidy_fit <- broom::tidy(fit)\n",
    "    glance   <- broom::glance(fit)\n",
    "    \n",
    "    term_name <- \"resp_value:condition\"\n",
    "    row_int   <- tidy_fit[tidy_fit$term == term_name, ]\n",
    "    \n",
    "    if (nrow(row_int) == 1) {\n",
    "      est <- row_int$estimate\n",
    "      se  <- row_int$std.error\n",
    "      t   <- row_int$statistic\n",
    "      p   <- row_int$p.value\n",
    "    } else {\n",
    "      est <- se <- t <- p <- NA_real_\n",
    "    }\n",
    "    \n",
    "    reg_results[[reg_idx]] <- data.frame(\n",
    "      outcome          = y,\n",
    "      resp_type        = resp,\n",
    "      N                = nrow(df_model),\n",
    "      n_subjects       = length(unique(df_model$record_id)),\n",
    "      beta_interaction = est,\n",
    "      se_interaction   = se,\n",
    "      t_interaction    = t,\n",
    "      p_interaction    = p,\n",
    "      r_squared        = glance$r.squared,\n",
    "      adj_r_squared    = glance$adj.r.squared,\n",
    "      covariates       = if (length(covariates) > 0) paste(covariates, collapse = \", \") else \"none\",\n",
    "      stringsAsFactors = FALSE\n",
    "    )\n",
    "    reg_idx <- reg_idx + 1\n",
    "  }\n",
    "}\n",
    "\n",
    "dev.off()  # close fatigue_lm_diagnosticcheck.pdf\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Combine and save regression table\n",
    "# --------------------------------------------------\n",
    "fatigue_lm_regressionresults <- bind_rows(reg_results)\n",
    "\n",
    "write.csv(\n",
    "  fatigue_lm_regressionresults,\n",
    "  \"fatigue_lm_regressionresults.csv\",\n",
    "  row.names = FALSE\n",
    ")\n",
    "\n",
    "cat(\"\\n✅ DONE (LM models)!\\n\")\n",
    "cat(\"• Interaction results saved to: fatigue_lm_regressionresults.csv\\n\")\n",
    "cat(\"• Diagnostics PDF saved as: fatigue_lm_diagnosticcheck.pdf\\n\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Scatterplots with regression lines for significant interactions\n",
    "# --------------------------------------------------\n",
    "sig_threshold <- 0.05\n",
    "\n",
    "sig_rows <- fatigue_lm_regressionresults %>%\n",
    "  filter(!is.na(p_interaction) & p_interaction < sig_threshold)\n",
    "\n",
    "pdf(\"fatigue_lm_scatterplot.pdf\", width = 8, height = 6)\n",
    "\n",
    "if (nrow(sig_rows) > 0) {\n",
    "  for (i in seq_len(nrow(sig_rows))) {\n",
    "    y    <- sig_rows$outcome[i]\n",
    "    resp <- sig_rows$resp_type[i]\n",
    "    \n",
    "    df_plot <- df_prepost %>%\n",
    "      filter(resp_type == resp) %>%\n",
    "      dplyr::select(record_id, condition, resp_value, all_of(y)) %>%\n",
    "      na.omit()\n",
    "    \n",
    "    p_scatter <- ggplot(\n",
    "      df_plot,\n",
    "      aes(x = resp_value, y = .data[[y]], color = factor(condition))\n",
    "    ) +\n",
    "      geom_point() +\n",
    "      geom_smooth(method = \"lm\", se = FALSE) +\n",
    "      labs(\n",
    "        title = paste0(\n",
    "          \"Scatterplot with Regression Lines by Condition\\n\",\n",
    "          y, \" vs \", resp, \" (significant interaction)\"\n",
    "        ),\n",
    "        x     = paste0(resp, \" (resp_value)\"),\n",
    "        y     = y,\n",
    "        color = \"Condition\\n(0 = pre, 1 = post)\"\n",
    "      )\n",
    "    \n",
    "    print(p_scatter)\n",
    "  }\n",
    "} else {\n",
    "  # If no significant interactions, create a placeholder page\n",
    "  plot.new()\n",
    "  title(\"No significant interactions (p < 0.05)\\nNo scatterplots generated.\")\n",
    "}\n",
    "\n",
    "dev.off()  # close fatigue_lm_scatterplot.pdf\n",
    "\n",
    "cat(\"• Scatterplots PDF saved as: fatigue_lm_scatterplot.pdf\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe70700",
   "metadata": {},
   "source": [
    "## Mixed effects model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53f0c33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary (singular) fit: see help('isSingular')\n",
      "\n",
      "boundary (singular) fit: see help('isSingular')\n",
      "\n",
      "boundary (singular) fit: see help('isSingular')\n",
      "\n",
      "boundary (singular) fit: see help('isSingular')\n",
      "\n",
      "boundary (singular) fit: see help('isSingular')\n",
      "\n",
      "boundary (singular) fit: see help('isSingular')\n",
      "\n",
      "boundary (singular) fit: see help('isSingular')\n",
      "\n",
      "boundary (singular) fit: see help('isSingular')\n",
      "\n",
      "\n",
      "✅ DONE!\n",
      "• NB GLMMs fit with three random structures per outcome × resp_type\n",
      "• Model comparison saved to: fatigue_glmm_model_comparison.csv\n",
      "• Interaction term results saved to: fatigue_glmm_regressionresults.csv\n"
     ]
    }
   ],
   "source": [
    "library(dplyr)\n",
    "library(tidyr)\n",
    "library(lme4)   # for glmer.nb\n",
    "\n",
    "# --------------------------------------------------\n",
    "# CONFIGURATION\n",
    "# --------------------------------------------------\n",
    "covariates    <- c(\"data_age\", \"subject_female\")\n",
    "outcomes      <- c(\"fss_sum\", \"woods_sum\", \"dsq_sum\")\n",
    "resp_types    <- c(\"mip\", \"smip\", \"fit\", \"id\", \"slopesmip\", \"sindex\", \"pif\", \"volume\")\n",
    "condition_var <- \"condition\"   # 0 = pre, 1 = post\n",
    "\n",
    "# We assume df_long has columns like mip_pre_max, mip_post_max, etc.\n",
    "# --------------------------------------------------\n",
    "# Create long format dataframe for pre/post analysis\n",
    "# --------------------------------------------------\n",
    "df_prepost <- df_long %>%\n",
    "  filter(time_point %in% c(1, 2)) %>%\n",
    "  mutate(condition = ifelse(time_point == 1, 0, 1)) %>%\n",
    "  dplyr::select(\n",
    "    record_id,\n",
    "    condition,\n",
    "    all_of(outcomes),\n",
    "    matches(paste0(\"^(\", paste(resp_types, collapse = \"|\"), \")_(pre|post)_max$\")),\n",
    "    all_of(covariates)\n",
    "  ) %>%\n",
    "  pivot_longer(\n",
    "    cols = matches(paste0(\"^(\", paste(resp_types, collapse = \"|\"), \")_(pre|post)_max$\")),\n",
    "    names_to      = c(\"resp_type\", \"time\", \".value\"),\n",
    "    names_pattern = \"(.+)_(pre|post)_(.+)\"\n",
    "  ) %>%\n",
    "  rename(resp_value = max) %>%\n",
    "  filter(!is.na(resp_value)) %>%\n",
    "  distinct()\n",
    "\n",
    "# Quick sanity check: should be ~ 2 rows per subject per resp_type\n",
    "# df_prepost %>% count(record_id, resp_type, condition)\n",
    "\n",
    "\n",
    "library(dplyr)\n",
    "library(lme4)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Storage objects\n",
    "# --------------------------------------------------\n",
    "model_comp_list <- list()  # for fatigue_glmm_model_comparison.csv\n",
    "reg_results     <- list()  # for fatigue_glmm_regressionresults.csv\n",
    "comp_idx        <- 1\n",
    "reg_idx         <- 1\n",
    "\n",
    "for (y in outcomes) {\n",
    "  for (resp in resp_types) {\n",
    "    \n",
    "    # Subset to this respiratory measure\n",
    "    df_model <- df_prepost %>%\n",
    "      filter(resp_type == resp) %>%\n",
    "      dplyr::select(record_id, condition, resp_value, all_of(y), all_of(covariates)) %>%\n",
    "      na.omit()\n",
    "    \n",
    "    # Need at least 2 rows per subject and both conditions present\n",
    "    if (nrow(df_model) < 10) next\n",
    "    if (length(unique(df_model[[condition_var]])) < 2) next\n",
    "    if (length(unique(df_model$record_id)) < 5) next  # arbitrary small sample guard\n",
    "    \n",
    "    # --------------------------------------------------\n",
    "    # Fixed part of the formula\n",
    "    # outcome ~ resp_value * condition + covariates\n",
    "    # --------------------------------------------------\n",
    "    if (length(covariates) > 0) {\n",
    "      fixed_rhs <- paste(\"resp_value * condition\", paste(covariates, collapse = \" + \"), sep = \" + \")\n",
    "    } else {\n",
    "      fixed_rhs <- \"resp_value * condition\"\n",
    "    }\n",
    "    \n",
    "    # Random structures\n",
    "    form_int   <- as.formula(paste(y, \"~\", fixed_rhs, \"+ (1 | record_id)\"))\n",
    "    form_slope <- as.formula(paste(y, \"~\", fixed_rhs, \"+ (0 + resp_value | record_id)\"))\n",
    "    form_both  <- as.formula(paste(y, \"~\", fixed_rhs, \"+ (1 + resp_value | record_id)\"))\n",
    "    \n",
    "    # --------------------------------------------------\n",
    "    # Fit models with tryCatch to avoid crashes\n",
    "    # --------------------------------------------------\n",
    "    fit_int <- tryCatch(\n",
    "      suppressWarnings(\n",
    "        glmer.nb(form_int, data = df_model,\n",
    "                control = glmerControl(optimizer = \"bobyqa\", optCtrl = list(maxfun = 2e5)))\n",
    "      ),\n",
    "      error = function(e) NULL\n",
    "    )\n",
    "\n",
    "    fit_slope <- tryCatch(\n",
    "      suppressWarnings(\n",
    "        glmer.nb(form_slope, data = df_model,\n",
    "                control = glmerControl(optimizer = \"bobyqa\", optCtrl = list(maxfun = 2e5)))\n",
    "      ),\n",
    "      error = function(e) NULL\n",
    "    )\n",
    "\n",
    "    fit_both <- tryCatch(\n",
    "      suppressWarnings(\n",
    "        glmer.nb(form_both, data = df_model,\n",
    "                control = glmerControl(optimizer = \"bobyqa\", optCtrl = list(maxfun = 2e5)))\n",
    "      ),\n",
    "      error = function(e) NULL\n",
    "    )\n",
    "    \n",
    "    # --------------------------------------------------\n",
    "    # Collect AICs\n",
    "    # --------------------------------------------------\n",
    "    aic_int   <- if (!is.null(fit_int))   AIC(fit_int)   else NA_real_\n",
    "    aic_slope <- if (!is.null(fit_slope)) AIC(fit_slope) else NA_real_\n",
    "    aic_both  <- if (!is.null(fit_both))  AIC(fit_both)  else NA_real_\n",
    "    \n",
    "    aic_vec <- c(random_intercept = aic_int,\n",
    "                 random_slope     = aic_slope,\n",
    "                 random_int_slope = aic_both)\n",
    "    \n",
    "    # If all failed, skip\n",
    "    if (all(is.na(aic_vec))) next\n",
    "    \n",
    "    # Choose best random structure\n",
    "    best_name <- names(which.min(aic_vec))\n",
    "    best_fit  <- switch(\n",
    "      best_name,\n",
    "      random_intercept = fit_int,\n",
    "      random_slope     = fit_slope,\n",
    "      random_int_slope = fit_both\n",
    "    )\n",
    "    \n",
    "    # Just in case\n",
    "    if (is.null(best_fit)) next\n",
    "    \n",
    "    # Save model comparison info\n",
    "    model_comp_list[[comp_idx]] <- data.frame(\n",
    "      outcome       = y,\n",
    "      resp_type     = resp,\n",
    "      N             = nrow(df_model),\n",
    "      n_subjects    = length(unique(df_model$record_id)),\n",
    "      covariates    = if (length(covariates) > 0) paste(covariates, collapse = \", \") else \"none\",\n",
    "      AIC_random_intercept   = aic_int,\n",
    "      AIC_random_slope       = aic_slope,\n",
    "      AIC_random_int_slope   = aic_both,\n",
    "      best_random_structure  = best_name,\n",
    "      stringsAsFactors       = FALSE\n",
    "    )\n",
    "    comp_idx <- comp_idx + 1\n",
    "    \n",
    "    # --------------------------------------------------\n",
    "    # Extract interaction term from best model\n",
    "    # --------------------------------------------------\n",
    "    coef_mat <- summary(best_fit)$coefficients\n",
    "    # For numeric 0/1 condition, interaction is resp_value:condition\n",
    "    term_name <- \"resp_value:condition\"\n",
    "    \n",
    "    if (term_name %in% rownames(coef_mat)) {\n",
    "      est <- coef_mat[term_name, \"Estimate\"]\n",
    "      se  <- coef_mat[term_name, \"Std. Error\"]\n",
    "      z   <- coef_mat[term_name, \"z value\"]\n",
    "      p   <- coef_mat[term_name, \"Pr(>|z|)\"]\n",
    "    } else {\n",
    "      est <- se <- z <- p <- NA_real_\n",
    "    }\n",
    "    \n",
    "    reg_results[[reg_idx]] <- data.frame(\n",
    "      outcome          = y,\n",
    "      resp_type        = resp,\n",
    "      best_random_str  = best_name,\n",
    "      N                = nrow(df_model),\n",
    "      n_subjects       = length(unique(df_model$record_id)),\n",
    "      beta_interaction = est,\n",
    "      se_interaction   = se,\n",
    "      z_interaction    = z,\n",
    "      p_interaction    = p,\n",
    "      covariates       = if (length(covariates) > 0) paste(covariates, collapse = \", \") else \"none\",\n",
    "      stringsAsFactors = FALSE\n",
    "    )\n",
    "    reg_idx <- reg_idx + 1\n",
    "  }\n",
    "}\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Save outputs as CSVs\n",
    "# --------------------------------------------------\n",
    "fatigue_glmm_model_comparison <- bind_rows(model_comp_list)\n",
    "write.csv(\n",
    "  fatigue_glmm_model_comparison,\n",
    "  \"fatigue_glmm_model_comparison.csv\",\n",
    "  row.names = FALSE\n",
    ")\n",
    "\n",
    "fatigue_glmm_regressionresults <- bind_rows(reg_results)\n",
    "write.csv(\n",
    "  fatigue_glmm_regressionresults,\n",
    "  \"fatigue_glmm_regressionresults.csv\",\n",
    "  row.names = FALSE\n",
    ")\n",
    "\n",
    "cat(\"\\n✅ DONE!\\n\")\n",
    "cat(\"• NB GLMMs fit with three random structures per outcome × resp_type\\n\")\n",
    "cat(\"• Model comparison saved to: fatigue_glmm_model_comparison.csv\\n\")\n",
    "cat(\"• Interaction term results saved to: fatigue_glmm_regressionresults.csv\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af2cd8f",
   "metadata": {},
   "source": [
    "# Group Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4caa6998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running comparison: mip_pre_max vs mip_post_max \n",
      "Running comparison: mip_pre_max_percentpredict_1 vs mip_post_max_percentpredict_1 \n",
      "Running comparison: mip_pre_max_percentpredict_2 vs mip_post_max_percentpredict_2 \n",
      "Running comparison: mip_pre_max_percentpredict_3 vs mip_post_max_percentpredict_3 \n",
      "Running comparison: smip_pre_max vs smip_post_max \n",
      "Running comparison: fit_pre_max vs fit_post_max \n",
      "Running comparison: pif_pre_max vs pif_post_max \n",
      "Running comparison: sindex_pre_max vs sindex_post_max \n",
      "Running comparison: volume_pre_max vs volume_post_max \n",
      "Running comparison: id_pre_max vs id_post_max \n",
      "Running comparison: slopesmip_pre_max vs slopesmip_post_max \n",
      "\n",
      "==============================================\n",
      " PRE vs POST ACTIVITY PAIRED COMPARISONS\n",
      "==============================================\n",
      "\n",
      "Comparison 1: mip_pre_max vs mip_post_max\n",
      "N pairs: 22 | Pre: 47.68 | Post: 46.14 | Difference: -1.55 (Decrease)\n",
      "Paired t-test: t = 0.467, p = 0.6453 \n",
      "Wilcoxon test: W = 150.0, p = 0.4550 \n",
      "Consistent significance: No\n",
      "----------------------------------------------\n",
      "\n",
      "Comparison 2: mip_pre_max_percentpredict_1 vs mip_post_max_percentpredict_1\n",
      "N pairs: 22 | Pre: 55.21 | Post: 53.26 | Difference: -1.95 (Decrease)\n",
      "Paired t-test: t = 0.544, p = 0.5921 \n",
      "Wilcoxon test: W = 148.0, p = 0.4954 \n",
      "Consistent significance: No\n",
      "----------------------------------------------\n",
      "\n",
      "Comparison 3: mip_pre_max_percentpredict_2 vs mip_post_max_percentpredict_2\n",
      "N pairs: 22 | Pre: 44.88 | Post: 43.49 | Difference: -1.40 (Decrease)\n",
      "Paired t-test: t = 0.470, p = 0.6431 \n",
      "Wilcoxon test: W = 149.0, p = 0.4751 \n",
      "Consistent significance: No\n",
      "----------------------------------------------\n",
      "\n",
      "Comparison 4: mip_pre_max_percentpredict_3 vs mip_post_max_percentpredict_3\n",
      "N pairs: 22 | Pre: 55.12 | Post: 53.37 | Difference: -1.75 (Decrease)\n",
      "Paired t-test: t = 0.485, p = 0.6330 \n",
      "Wilcoxon test: W = 151.0, p = 0.4359 \n",
      "Consistent significance: No\n",
      "----------------------------------------------\n",
      "\n",
      "Comparison 5: smip_pre_max vs smip_post_max\n",
      "N pairs: 22 | Pre: 246.00 | Post: 195.36 | Difference: -50.64 (Decrease)\n",
      "Paired t-test: t = 2.925, p = 0.0081 **\n",
      "Wilcoxon test: W = 188.0, p = 0.0123 *\n",
      "Consistent significance: Yes\n",
      "----------------------------------------------\n",
      "\n",
      "Comparison 6: fit_pre_max vs fit_post_max\n",
      "N pairs: 22 | Pre: 15.20 | Post: 10.82 | Difference: -4.38 (Decrease)\n",
      "Paired t-test: t = 2.533, p = 0.0193 *\n",
      "Wilcoxon test: W = 149.5, p = 0.0298 *\n",
      "Consistent significance: Yes\n",
      "----------------------------------------------\n",
      "\n",
      "Comparison 7: pif_pre_max vs pif_post_max\n",
      "N pairs: 22 | Pre: 2.90 | Post: 3.08 | Difference: 0.19 (Increase)\n",
      "Paired t-test: t = -1.490, p = 0.1510 \n",
      "Wilcoxon test: W = 68.5, p = 0.1784 \n",
      "Consistent significance: No\n",
      "----------------------------------------------\n",
      "\n",
      "Comparison 8: sindex_pre_max vs sindex_post_max\n",
      "N pairs: 22 | Pre: 50.55 | Post: 53.64 | Difference: 3.09 (Increase)\n",
      "Paired t-test: t = -1.438, p = 0.1653 \n",
      "Wilcoxon test: W = 76.5, p = 0.1805 \n",
      "Consistent significance: No\n",
      "----------------------------------------------\n",
      "\n",
      "Comparison 9: volume_pre_max vs volume_post_max\n",
      "N pairs: 22 | Pre: 2.49 | Post: 2.42 | Difference: -0.07 (Decrease)\n",
      "Paired t-test: t = 0.834, p = 0.4137 \n",
      "Wilcoxon test: W = 93.5, p = 0.4342 \n",
      "Consistent significance: No\n",
      "----------------------------------------------\n",
      "\n",
      "Comparison 10: id_pre_max vs id_post_max\n",
      "N pairs: 16 | Pre: 6.94 | Post: 6.31 | Difference: -0.63 (Decrease)\n",
      "Paired t-test: t = 1.170, p = 0.2601 \n",
      "Wilcoxon test: W = 77.5, p = 0.3342 \n",
      "Consistent significance: No\n",
      "----------------------------------------------\n",
      "\n",
      "Comparison 11: slopesmip_pre_max vs slopesmip_post_max\n",
      "N pairs: 16 | Pre: 14.82 | Post: 17.56 | Difference: 2.73 (Increase)\n",
      "Paired t-test: t = -1.235, p = 0.2357 \n",
      "Wilcoxon test: W = 52.0, p = 0.4229 \n",
      "Consistent significance: No\n",
      "----------------------------------------------\n",
      "\n",
      "==============================================\n",
      " SUMMARY: SIGNIFICANT PRE-POST DIFFERENCES\n",
      "==============================================\n",
      "1. smip: 246.00 → 195.36 (Δ-50.64, Decrease), p = 0.0123\n",
      "2. fit: 15.20 → 10.82 (Δ-4.38, Decrease), p = 0.0298\n",
      "\n",
      "Detailed results saved to 'pre_post_paired_comparisons.csv'\n"
     ]
    }
   ],
   "source": [
    "library(dplyr)\n",
    "library(broom)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Define respiratory variables\n",
    "# --------------------------------------------------\n",
    "resp_vars <- c(\"mip_pre_max\", \"mip_pre_max_percentpredict_1\", \"mip_pre_max_percentpredict_2\", \"mip_pre_max_percentpredict_3\",\n",
    "               \"smip_pre_max\", \"fit_pre_max\", \"pif_pre_max\", \"sindex_pre_max\", \"volume_pre_max\",\n",
    "               \"id_pre_max\", \"slopesmip_pre_max\",\n",
    "               \"mip_post_max\", \"mip_post_max_percentpredict_1\", \"mip_post_max_percentpredict_2\", \"mip_post_max_percentpredict_3\",\n",
    "               \"smip_post_max\",\"fit_post_max\", \"pif_post_max\", \"sindex_post_max\",\n",
    "               \"volume_post_max\", \"id_post_max\", \"slopesmip_post_max\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Create pre-post pairs\n",
    "# --------------------------------------------------\n",
    "\n",
    "df_v1 <- df_long %>%\n",
    "  filter(time_point == 1)\n",
    "\n",
    "\n",
    "# Extract base variable names (without pre/post)\n",
    "base_vars <- unique(gsub(\"_(pre|post)_max.*\", \"\", resp_vars))\n",
    "base_vars <- base_vars[!base_vars %in% c(\"\", \"slopesmip\")]  # Remove empty strings\n",
    "\n",
    "# Create pairing list\n",
    "pre_post_pairs <- list()\n",
    "\n",
    "for (base_var in base_vars) {\n",
    "  # Find all pre and post variables for this base variable\n",
    "  pre_vars <- resp_vars[grepl(paste0(\"^\", base_var, \"_pre_max\"), resp_vars)]\n",
    "  post_vars <- resp_vars[grepl(paste0(\"^\", base_var, \"_post_max\"), resp_vars)]\n",
    "  \n",
    "  # Pair them based on the suffix\n",
    "  for (pre_var in pre_vars) {\n",
    "    suffix <- gsub(paste0(base_var, \"_pre_max\"), \"\", pre_var)\n",
    "    post_var <- paste0(base_var, \"_post_max\", suffix)\n",
    "    \n",
    "    if (post_var %in% post_vars) {\n",
    "      pre_post_pairs[[length(pre_post_pairs) + 1]] <- c(pre_var, post_var)\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "# Special handling for slopesmip\n",
    "if (\"slopesmip_pre_max\" %in% resp_vars & \"slopesmip_post_max\" %in% resp_vars) {\n",
    "  pre_post_pairs[[length(pre_post_pairs) + 1]] <- c(\"slopesmip_pre_max\", \"slopesmip_post_max\")\n",
    "}\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Function to run paired tests\n",
    "# --------------------------------------------------\n",
    "run_paired_tests <- function(pre_var, post_var, data) {\n",
    "  # Filter to participants with both pre and post values\n",
    "  paired_data <- data %>%\n",
    "    dplyr::select(record_id, all_of(c(pre_var, post_var))) %>%\n",
    "    na.omit()\n",
    "  \n",
    "  n_pairs <- nrow(paired_data)\n",
    "  \n",
    "  if (n_pairs < 10) {\n",
    "    return(data.frame(\n",
    "      pre_var = pre_var,\n",
    "      post_var = post_var,\n",
    "      n_pairs = n_pairs,\n",
    "      pre_mean = NA,\n",
    "      post_mean = NA,\n",
    "      mean_diff = NA,\n",
    "      t_statistic = NA,\n",
    "      t_p_value = NA,\n",
    "      w_statistic = NA,\n",
    "      w_p_value = NA,\n",
    "      stringsAsFactors = FALSE\n",
    "    ))\n",
    "  }\n",
    "  \n",
    "  # Calculate means\n",
    "  pre_mean <- mean(paired_data[[pre_var]], na.rm = TRUE)\n",
    "  post_mean <- mean(paired_data[[post_var]], na.rm = TRUE)\n",
    "  mean_diff <- post_mean - pre_mean\n",
    "  \n",
    "  # Paired t-test\n",
    "  t_test <- tryCatch({\n",
    "    t.test(paired_data[[pre_var]], paired_data[[post_var]], paired = TRUE)\n",
    "  }, error = function(e) {\n",
    "    list(statistic = NA, p.value = NA)\n",
    "  })\n",
    "  \n",
    "  # Wilcoxon signed-rank test\n",
    "  w_test <- tryCatch({\n",
    "    wilcox.test(paired_data[[pre_var]], paired_data[[post_var]], paired = TRUE, exact = FALSE)\n",
    "  }, error = function(e) {\n",
    "    list(statistic = NA, p.value = NA)\n",
    "  })\n",
    "  \n",
    "  return(data.frame(\n",
    "    pre_var = pre_var,\n",
    "    post_var = post_var,\n",
    "    n_pairs = n_pairs,\n",
    "    pre_mean = pre_mean,\n",
    "    post_mean = post_mean,\n",
    "    mean_diff = mean_diff,\n",
    "    t_statistic = ifelse(is.null(t_test$statistic), NA, t_test$statistic),\n",
    "    t_p_value = ifelse(is.null(t_test$p.value), NA, t_test$p.value),\n",
    "    w_statistic = ifelse(is.null(w_test$statistic), NA, w_test$statistic),\n",
    "    w_p_value = ifelse(is.null(w_test$p.value), NA, w_test$p.value),\n",
    "    stringsAsFactors = FALSE\n",
    "  ))\n",
    "}\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Run all paired comparisons\n",
    "# --------------------------------------------------\n",
    "paired_results <- list()\n",
    "\n",
    "for (i in seq_along(pre_post_pairs)) {\n",
    "  pair <- pre_post_pairs[[i]]\n",
    "  cat(\"Running comparison:\", pair[1], \"vs\", pair[2], \"\\n\")\n",
    "  \n",
    "  result <- run_paired_tests(pair[1], pair[2], df_v1)\n",
    "  paired_results[[i]] <- result\n",
    "}\n",
    "\n",
    "paired_df <- bind_rows(paired_results)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Format and clean up results\n",
    "# --------------------------------------------------\n",
    "formatted_paired <- paired_df %>%\n",
    "  mutate(\n",
    "    pre_mean = round(pre_mean, 2),\n",
    "    post_mean = round(post_mean, 2),\n",
    "    mean_diff = round(mean_diff, 2),\n",
    "    t_statistic = round(t_statistic, 3),\n",
    "    t_p_value = round(t_p_value, 4),\n",
    "    w_statistic = round(w_statistic, 1),\n",
    "    w_p_value = round(w_p_value, 4),\n",
    "    t_sig = case_when(\n",
    "      t_p_value < 0.001 ~ \"***\",\n",
    "      t_p_value < 0.01 ~ \"**\",\n",
    "      t_p_value < 0.05 ~ \"*\",\n",
    "      TRUE ~ \"\"\n",
    "    ),\n",
    "    w_sig = case_when(\n",
    "      w_p_value < 0.001 ~ \"***\",\n",
    "      w_p_value < 0.01 ~ \"**\",\n",
    "      w_p_value < 0.05 ~ \"*\",\n",
    "      TRUE ~ \"\"\n",
    "    ),\n",
    "    # Add interpretation\n",
    "    direction = ifelse(mean_diff > 0, \"Increase\", \"Decrease\"),\n",
    "    consistent_significance = ifelse(t_p_value < 0.05 & w_p_value < 0.05, \"Yes\", \"No\")\n",
    "  ) %>%\n",
    "  dplyr::select(\n",
    "    pre_var, post_var, n_pairs,\n",
    "    pre_mean, post_mean, mean_diff, direction,\n",
    "    t_statistic, t_p_value, t_sig,\n",
    "    w_statistic, w_p_value, w_sig,\n",
    "    consistent_significance\n",
    "  )\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Print results\n",
    "# --------------------------------------------------\n",
    "cat(\"\\n==============================================\\n\")\n",
    "cat(\" PRE vs POST ACTIVITY PAIRED COMPARISONS\\n\")\n",
    "cat(\"==============================================\\n\")\n",
    "\n",
    "for (i in 1:nrow(formatted_paired)) {\n",
    "  row <- formatted_paired[i, ]\n",
    "  cat(sprintf(\"\\nComparison %d: %s vs %s\\n\", i, row$pre_var, row$post_var))\n",
    "  cat(sprintf(\"N pairs: %d | Pre: %.2f | Post: %.2f | Difference: %.2f (%s)\\n\", \n",
    "              row$n_pairs, row$pre_mean, row$post_mean, row$mean_diff, row$direction))\n",
    "  cat(sprintf(\"Paired t-test: t = %.3f, p = %.4f %s\\n\", \n",
    "              row$t_statistic, row$t_p_value, row$t_sig))\n",
    "  cat(sprintf(\"Wilcoxon test: W = %.1f, p = %.4f %s\\n\", \n",
    "              row$w_statistic, row$w_p_value, row$w_sig))\n",
    "  cat(sprintf(\"Consistent significance: %s\\n\", row$consistent_significance))\n",
    "  cat(\"----------------------------------------------\\n\")\n",
    "}\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Summary of significant results\n",
    "# --------------------------------------------------\n",
    "sig_results <- formatted_paired %>%\n",
    "  filter(consistent_significance == \"Yes\")\n",
    "\n",
    "cat(\"\\n==============================================\\n\")\n",
    "cat(\" SUMMARY: SIGNIFICANT PRE-POST DIFFERENCES\\n\")\n",
    "cat(\"==============================================\\n\")\n",
    "if (nrow(sig_results) > 0) {\n",
    "  for (i in 1:nrow(sig_results)) {\n",
    "    row <- sig_results[i, ]\n",
    "    cat(sprintf(\"%d. %s: %.2f → %.2f (Δ%.2f, %s), p = %.4f\\n\", \n",
    "                i, gsub(\"_pre_max.*\", \"\", row$pre_var),\n",
    "                row$pre_mean, row$post_mean, row$mean_diff, row$direction,\n",
    "                max(row$t_p_value, row$w_p_value, na.rm = TRUE)))\n",
    "  }\n",
    "} else {\n",
    "  cat(\"No consistently significant pre-post differences found.\\n\")\n",
    "}\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Save results\n",
    "# --------------------------------------------------\n",
    "write.csv(formatted_paired, \"pre_post_paired_comparisons.csv\", row.names = FALSE)\n",
    "cat(\"\\nDetailed results saved to 'pre_post_paired_comparisons.csv'\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc2a143",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "r"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
