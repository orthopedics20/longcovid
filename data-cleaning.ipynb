{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "870814dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.max_rows', None)  # Show all rows\n",
    "\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296947fb",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce610da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RedcapExport.csv as redcap\n",
    "redcap = pd.read_csv('Redcap Export.csv')\n",
    "\n",
    "# Step 1. Extract covid_group and interventiongroup from 'screening_arm_1' rows\n",
    "# and map them to all rows with the same record_id\n",
    "\n",
    "# Create a small DataFrame containing just screening_arm_1 rows\n",
    "screening_data = redcap[redcap['redcap_event_name'] == 'screening_arm_1']\n",
    "\n",
    "# Build a mapping dictionary for covid_group and interventiongroup\n",
    "covid_group_map = screening_data.set_index('record_id')['covid_group'].to_dict()\n",
    "interventiongroup_map = screening_data.set_index('record_id')['interventiongroup'].to_dict()\n",
    "\n",
    "# Fill missing values in covid_group and interventiongroup columns across all rows\n",
    "redcap['covid_group'] = redcap.apply(\n",
    "    lambda row: covid_group_map.get(row['record_id'], row['covid_group']),\n",
    "    axis=1\n",
    ")\n",
    "redcap['interventiongroup'] = redcap.apply(\n",
    "    lambda row: interventiongroup_map.get(row['record_id'], row['interventiongroup']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Step 2. Remove 'screening_arm_1' rows\n",
    "redcap = redcap[redcap['redcap_event_name'].isin(['baseline_arm_1', 'visit_2_arm_1'])]\n",
    "\n",
    "# Step 3. Create the time_point column\n",
    "time_point_map = {\n",
    "    'baseline_arm_1': 1,\n",
    "    'visit_2_arm_1': 2\n",
    "}\n",
    "redcap['time_point'] = redcap['redcap_event_name'].map(time_point_map)\n",
    "\n",
    "# ---------------------------------------------------------------------------- #\n",
    "\n",
    "# NOTE: Remember to update RedCAP (FIX THIS)\n",
    "# Step 4. Manually overwrite interventiongroup using your dictionary\n",
    "manual_interventiongroup = {\n",
    "    1:1, 2:0, 3:1, 4:0, 5:0, 6:0, 7:1, 8:1, 9:0, 10:1,\n",
    "    13:1, 14:0, 15:0, 16:0, 17:0, 18:1, 20:0, 21:1, 25:1, 29:1\n",
    "}\n",
    "redcap['interventiongroup'] = redcap['record_id'].map(manual_interventiongroup).combine_first(redcap['interventiongroup'])\n",
    "\n",
    "# Add the name mapping (from your previous request)\n",
    "name_mapping = {\n",
    "    1: 'michelle', 2: 'gay', 3: 'maria', 4: 'kevin', 5: 'jimmy',\n",
    "    6: 'blanca', 7: 'joyti', 8: 'mary', 9: 'monika', 10: 'carlos', 11: 'marty',\n",
    "    12: 'bri', 13: 'michael', 14: 'howard', 15: 'alyssa', 16: 'alice', 17: 'tatum',\n",
    "    18: 'anjie', 19: 'shavonne', 20: 'sam', 21: 'morgan', 22: 'michael', 23: 'margaret',\n",
    "    24: 'kloe', 25: 'wendy', 26: 'ethel', 27: 'conor', 28: 'chris', 29: 'jay', 30: 'nancy h'\n",
    "}\n",
    "redcap['name'] = redcap['record_id'].map(name_mapping)\n",
    "\n",
    "# ---------------------------------------------------------------------------- #\n",
    "\n",
    "# Remove all columns where every value is NaN\n",
    "redcap = redcap.dropna(axis=1, how='all')\n",
    "\n",
    "# Drop unnecessary columns\n",
    "redcap = redcap.drop(columns=['redcap_event_name', 'redcap_repeat_instance'])\n",
    "\n",
    "# Remove all columns that end with '_complete'\n",
    "redcap = redcap.loc[:, ~redcap.columns.str.endswith('_complete')]\n",
    "\n",
    "# Remove all columns that end with '_csv'\n",
    "redcap = redcap.loc[:, ~redcap.columns.str.endswith('_csv')]\n",
    "\n",
    "# Export the cleaned DataFrame to a new CSV file\n",
    "redcap.to_csv('cleaned_redcap_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d864ecca",
   "metadata": {},
   "source": [
    "# Demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca29727",
   "metadata": {},
   "source": [
    "## Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43eb16c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set subject_female\n",
    "redcap = redcap.sort_values(['record_id', 'time_point'])\n",
    "time_point_1_mask = redcap['time_point'] == 1\n",
    "redcap.loc[time_point_1_mask, 'subject_female'] = np.where(\n",
    "    redcap.loc[time_point_1_mask, 'subject_gender'] == 'Female', 1,\n",
    "    np.where(redcap.loc[time_point_1_mask, 'subject_gender'] == 'Male', 0, np.nan)\n",
    ")\n",
    "redcap['subject_female'] = redcap.groupby('record_id')['subject_female'].ffill()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5c026e",
   "metadata": {},
   "source": [
    "## Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "81e66c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Female  Male\n",
      "Hispanic or Latino                        4     1\n",
      "American Indian/Alaskan Native            0     0\n",
      "Asian                                     3     1\n",
      "Native Hawaiian or Pacific Islander       0     0\n",
      "Black or African American                 3     1\n",
      "White                                     6     8\n",
      "More than One Race                        3     0\n",
      "Unknown                                   0     0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Step 1 — Fill missing ethnicity within each record_id\n",
    "redcap['subject_ethnicity'] = (\n",
    "    redcap.groupby('record_id')['subject_ethnicity']\n",
    "          .transform(lambda x: x.ffill().bfill())\n",
    ")\n",
    "\n",
    "# Step 2 — Mapping function for categories\n",
    "def map_ethnicity(value):\n",
    "    if pd.isna(value):\n",
    "        return 'Unknown'\n",
    "    val = value.strip().lower()\n",
    "\n",
    "    # Check multi-race first\n",
    "    if ',' in val or 'more than' in val or ' and ' in val:\n",
    "        return 'More than One Race'\n",
    "    \n",
    "    # Now single-race checks\n",
    "    if 'hispanic' in val or 'latino' in val or 'latina' in val:\n",
    "        return 'Hispanic or Latino'\n",
    "    elif 'american indian' in val or 'alaskan' in val:\n",
    "        return 'American Indian/Alaskan Native'\n",
    "    elif 'filipino' in val:\n",
    "        return 'Asian'\n",
    "    elif 'indian' in val or 'asian' in val:\n",
    "        return 'Asian'\n",
    "    elif 'pacific islander' in val or 'hawaiian' in val:\n",
    "        return 'Native Hawaiian or Pacific Islander'\n",
    "    elif 'black' in val or 'african' in val:\n",
    "        return 'Black or African American'\n",
    "    elif 'white' in val:\n",
    "        return 'White'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "redcap['subject_ethnicity_categorized'] = redcap['subject_ethnicity'].apply(map_ethnicity)\n",
    "\n",
    "# Step 3 — Create pivot table\n",
    "categories_order = [\n",
    "    'Hispanic or Latino',\n",
    "    'American Indian/Alaskan Native',\n",
    "    'Asian',\n",
    "    'Native Hawaiian or Pacific Islander',\n",
    "    'Black or African American',\n",
    "    'White',\n",
    "    'More than One Race',\n",
    "    'Unknown'\n",
    "]\n",
    "\n",
    "final_table = (\n",
    "    redcap.pivot_table(\n",
    "        index='subject_ethnicity_categorized',\n",
    "        columns='subject_gender',\n",
    "        aggfunc='size',\n",
    "        fill_value=0\n",
    "    )\n",
    "    .reindex(categories_order)\n",
    "    .fillna(0)  # ensure no NaN, only 0\n",
    "    .astype(int)  # make sure they're integers, not floats\n",
    "    .rename_axis(index=None, columns=None)\n",
    ")\n",
    "\n",
    "print(final_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c296f764",
   "metadata": {},
   "source": [
    "# Respiratory Strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "11f501e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mip_predicted1(row):\n",
    "    # https://www.atsjournals.org/doi/full/10.1164/ajrccm.158.5.9712006\n",
    "    try:\n",
    "        age = float(row['data_age'])\n",
    "        weight = float(row['data_kilograms'])\n",
    "        \n",
    "        # Check gender using subject_female (1=Female, 0=Male, NaN=unknown)\n",
    "        if row['subject_female'] == 0:  # Male (since 0 = Male)\n",
    "            return 126 - (1.028 * age) + (0.343 * weight)\n",
    "        elif row['subject_female'] == 1:  # Female (since 1 = Female)\n",
    "            height = float(row['data_centimeters'])  # Ensure 'height_cm' exists\n",
    "            return 171 - (0.694 * age) + (0.861 * weight) - (0.743 * height)\n",
    "        else:\n",
    "            return None  # Unknown gender (NaN or other)\n",
    "    except (KeyError, ValueError, TypeError):\n",
    "        return None  # Missing data or invalid type\n",
    "    \n",
    "\n",
    "def calculate_mip_predicted2(row):\n",
    "    # https://pubmed.ncbi.nlm.nih.gov/25141521/\n",
    "    try:\n",
    "        age = float(row['data_age'])\n",
    "        weight = float(row['data_kilograms'])\n",
    "        \n",
    "        if row['subject_female'] == 0:  # Male\n",
    "            return 124.39 - (0.91 * age) + (0.63 * weight)\n",
    "        elif row['subject_female'] == 1:  # Female\n",
    "            return 77.57 - (0.59 * age) + (0.62 * weight)\n",
    "        else:\n",
    "            return None  # Unknown gender\n",
    "    except (KeyError, ValueError, TypeError):\n",
    "        return None  # Missing data or invalid type\n",
    "\n",
    "    \n",
    "def calculate_mip_predicted3(row):\n",
    "    # # J. A. Evans and W. A. Whitelaw, “The assessment of maximal respiratory mouth pressures in adults,” Respiratory Care, vol. 54, no. 10, pp. 1348–1359, 2009.\n",
    "    try:\n",
    "        age = float(row['data_age'])\n",
    "        weight = float(row['data_kilograms'])\n",
    "        \n",
    "        if row['subject_female'] == 0:  # Male\n",
    "            return 120 - (0.41 * age)\n",
    "        elif row['subject_female'] == 1:  # Female\n",
    "            return 108 - (0.61 * age)\n",
    "        else:\n",
    "            return None  # Unknown gender\n",
    "    except (KeyError, ValueError, TypeError):\n",
    "        return None  # Missing data or invalid type\n",
    "\n",
    "def calculate_sindex_predicted(row):\n",
    "    # https://www.jornaldepneumologia.com.br/details/4136/en-US/maximal-dynamic-inspiratory-pressure--s-index-prediction-values-and-diagnosis-accuracy\n",
    "    try:\n",
    "        age = float(row['data_age'])\n",
    "        weight = float(row['data_kilograms'])\n",
    "        height = float(row['data_centimeters'])\n",
    "\n",
    "        if row['subject_female'] == 0: # Male\n",
    "            return -32.3 + (0.47 * weight) - (0.39 * age) + (0.79 * height)\n",
    "        elif row['subject_female'] == 1: # Female\n",
    "            return -54 + (0.47 * weight) - (0.39 * age) + (0.79 * height)\n",
    "        else:\n",
    "            return None  # Unknown\n",
    "    except (KeyError, ValueError, TypeError):\n",
    "        return None  # Missing data or invalid type\n",
    "    \n",
    "# Compute predicted values\n",
    "redcap['mip_predicted1'] = redcap.apply(calculate_mip_predicted1, axis=1)\n",
    "redcap['mip_predicted2'] = redcap.apply(calculate_mip_predicted2, axis=1)\n",
    "redcap['mip_predicted3'] = redcap.apply(calculate_mip_predicted3, axis=1)\n",
    "redcap['sindex_predicted'] = redcap.apply(calculate_sindex_predicted, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45e624d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define measures (just the regular ones)\n",
    "measures = ['mip', 'pif', 'sindex', 'volume']  # Removed 'smip' since we'll handle it separately\n",
    "\n",
    "# Calculate max for pre and post columns (only max, no min/mean)\n",
    "for measure in measures:\n",
    "    # Pre columns\n",
    "    pre_cols = [f\"imt_{measure}_{i}_pre\" for i in [1, 2, 3]]\n",
    "    if all(col in redcap.columns for col in pre_cols):\n",
    "        redcap[f\"{measure}_pre_max\"] = redcap[pre_cols].max(axis=1, skipna=True)\n",
    "    else:\n",
    "        print(f\"⚠️ Warning: Missing pre columns for {measure}\")\n",
    "\n",
    "    # Post columns\n",
    "    post_cols = [f\"imt_{measure}_{i}_post\" for i in [1, 2, 3]]\n",
    "    if all(col in redcap.columns for col in post_cols):\n",
    "        redcap[f\"{measure}_post_max\"] = redcap[post_cols].max(axis=1, skipna=True)\n",
    "    else:\n",
    "        print(f\"⚠️ Warning: Missing post columns for {measure}\")\n",
    "\n",
    "# Now calculate fatigue and fatigue percent (only for max)\n",
    "for measure in measures:\n",
    "    pre_col = f\"{measure}_pre_max\"\n",
    "    post_col = f\"{measure}_post_max\"\n",
    "\n",
    "    if pre_col in redcap.columns and post_col in redcap.columns:\n",
    "        # Fatigue: pre - post\n",
    "        fatigue_col = f\"{measure}_max_fatigue\"\n",
    "        redcap[fatigue_col] = redcap[pre_col] - redcap[post_col]\n",
    "\n",
    "        # Fatigue Percent: (pre - post) / pre * 100\n",
    "        fatigue_percent_col = f\"{measure}_max_fatigue_percent\"\n",
    "        redcap[fatigue_percent_col] = ((redcap[pre_col] - redcap[post_col]) / redcap[pre_col]) * 100\n",
    "    else:\n",
    "        print(f\"⚠️ Warning: Missing columns for {measure}_max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "36d73ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, calculate max SMIP from the three trials\n",
    "smip_pre_cols = [f\"imt_smip_{i}_pre\" for i in [1, 2, 3]]\n",
    "smip_post_cols = [f\"imt_smip_{i}_post\" for i in [1, 2, 3]]\n",
    "\n",
    "if all(col in redcap.columns for col in smip_pre_cols + smip_post_cols):\n",
    "    # Find which trial has the max SMIP value for each participant\n",
    "    redcap['smip_pre_max'] = redcap[smip_pre_cols].max(axis=1, skipna=True)\n",
    "    redcap['smip_post_max'] = redcap[smip_post_cols].max(axis=1, skipna=True)\n",
    "    \n",
    "    # Find the trial number of the max SMIP for pre and post\n",
    "    # Using apply to extract the trial number from the column name with the max value\n",
    "    def get_trial_number(row, cols):\n",
    "        max_col = row[cols].idxmax()\n",
    "        return int(max_col.split('_')[2])  # Extract the number from 'imt_smip_2_pre'\n",
    "    \n",
    "    redcap['max_smip_pre_trial'] = redcap.apply(lambda row: get_trial_number(row, smip_pre_cols), axis=1)\n",
    "    redcap['max_smip_post_trial'] = redcap.apply(lambda row: get_trial_number(row, smip_post_cols), axis=1)\n",
    "    \n",
    "    # Now extract the corresponding ID, slopesmip, and fit values for the trial with max SMIP\n",
    "    for idx, row in redcap.iterrows():\n",
    "        # For pre values\n",
    "        trial_pre = row['max_smip_pre_trial']\n",
    "        redcap.at[idx, 'id_pre_max'] = redcap.at[idx, f'imt_id_{trial_pre}_pre']\n",
    "        redcap.at[idx, 'slopesmip_pre_max'] = redcap.at[idx, f'imt_slopesmip_{trial_pre}_pre']\n",
    "        redcap.at[idx, 'fit_pre_max'] = redcap.at[idx, f'imt_fit_{trial_pre}_pre']\n",
    "        \n",
    "        # For post values\n",
    "        trial_post = row['max_smip_post_trial']\n",
    "        redcap.at[idx, 'id_post_max'] = redcap.at[idx, f'imt_id_{trial_post}_post']\n",
    "        redcap.at[idx, 'slopesmip_post_max'] = redcap.at[idx, f'imt_slopesmip_{trial_post}_post']\n",
    "        redcap.at[idx, 'fit_post_max'] = redcap.at[idx, f'imt_fit_{trial_post}_post']\n",
    "    \n",
    "    # Calculate fatigue for SMIP and the special variables\n",
    "    redcap['smip_max_fatigue'] = redcap['smip_pre_max'] - redcap['smip_post_max']\n",
    "    redcap['smip_max_fatigue_percent'] = ((redcap['smip_pre_max'] - redcap['smip_post_max']) / redcap['smip_pre_max'].replace(0, np.nan)) * 100\n",
    "    \n",
    "    # Also calculate fatigue for the special variables if desired\n",
    "    redcap['id_max_fatigue'] = redcap['id_pre_max'] - redcap['id_post_max']\n",
    "    redcap['slopesmip_max_fatigue'] = redcap['slopesmip_pre_max'] - redcap['slopesmip_post_max']\n",
    "    redcap['fit_max_fatigue'] = redcap['fit_pre_max'] - redcap['fit_post_max']\n",
    "    \n",
    "else:\n",
    "    print(\"⚠️ Warning: Missing SMIP columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0b29a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percent of predicted values for MIP only (using max only)\n",
    "predicted_vars = ['predicted1', 'predicted2', 'predicted3']  # these should exist in your dataset: 'mip_predicted1', 'mip_predicted2'\n",
    "\n",
    "for timepoint in ['pre', 'post']:\n",
    "    measure_col = f\"mip_{timepoint}_max\"  # Only using max now\n",
    "    for pred_var in predicted_vars:\n",
    "        pred_col = f\"mip_{pred_var}\"\n",
    "        percentpredict_col = f\"mip_{timepoint}_max_percentpredict_{pred_var[-1]}\"\n",
    "        \n",
    "        if measure_col in redcap.columns and pred_col in redcap.columns:\n",
    "            redcap[percentpredict_col] = (redcap[measure_col] / redcap[pred_col]) * 100  # Multiply by 100 to get percentage\n",
    "        else:\n",
    "            print(f\"⚠️ Warning: Missing columns for {measure_col} or {pred_col}\")\n",
    "\n",
    "predicted_vars = ['predicted']  # only sindex now\n",
    "\n",
    "for timepoint in ['pre', 'post']:\n",
    "    measure_col = f\"sindex_{timepoint}_max\"  # Only using max now\n",
    "    for pred_var in predicted_vars:\n",
    "        pred_col = f\"sindex_{pred_var}\"\n",
    "        percentpredict_col = f\"sindex_{timepoint}_max_percentpredict\"\n",
    "        \n",
    "        if measure_col in redcap.columns and pred_col in redcap.columns:\n",
    "            redcap[percentpredict_col] = (redcap[measure_col] / redcap[pred_col]) * 100  # Multiply by 100 to get percentage\n",
    "        else:\n",
    "            print(f\"⚠️ Warning: Missing columns for {measure_col} or {pred_col}\")           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11c304d",
   "metadata": {},
   "source": [
    "# CPET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7bc23e",
   "metadata": {},
   "source": [
    "## Predicted VO2 Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d37cfe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert kilograms to pounds\n",
    "redcap['data_pounds'] = redcap['data_kilograms'] * 2.20462\n",
    "\n",
    "\n",
    "# https://www.sciencedirect.com/science/article/abs/pii/S0033062017300476 (also https://www.ajconline.org/article/S0002-9149(17)30873-1/abstract)\n",
    "redcap['cpet_vo2peak_predicted'] = (\n",
    "    79.9\n",
    "    - (0.39 * redcap['data_age'])\n",
    "    - (13.7 * redcap['subject_female'])\n",
    "    - (0.127 * redcap['data_pounds'])\n",
    ")\n",
    "\n",
    "# Percent of predicted VO2 max\n",
    "redcap['cpet_vo2peak_percentpredicted'] = (\n",
    "    redcap['cpet_vo2peak_relative'] / redcap['cpet_vo2peak_predicted']\n",
    ") * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f277843c",
   "metadata": {},
   "source": [
    "## Ventilation / Gas Exchange / Cardiac Classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "68997131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results ---\n",
      "cpet_gasexchangeimpairment     1\n",
      "cpet_ventilationimpairment    40\n",
      "cpet_cardiacimpairment        13\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Initialize impairment columns\n",
    "redcap[\"cpet_gasexchangeimpairment\"] = 0\n",
    "redcap[\"cpet_ventilationimpairment\"] = 0\n",
    "redcap[\"cpet_cardiacimpairment\"] = 0\n",
    "\n",
    "# Apply classification logic\n",
    "gas_exchange_mask = (redcap[\"cpet_petco2_at_vslope\"] < 36) & (redcap[\"cpet_vevco2slope_peak\"] >= 34)\n",
    "ventilation_mask = (redcap[\"cpet_petco2_at_vslope\"] < 36) & (redcap[\"cpet_vevco2slope_peak\"] < 34)\n",
    "cardiac_mask = (redcap[\"cpet_o2pulse\"] < 10)\n",
    "\n",
    "redcap.loc[gas_exchange_mask, \"cpet_gasexchangeimpairment\"] = 1\n",
    "redcap.loc[ventilation_mask, \"cpet_ventilationimpairment\"] = 1\n",
    "redcap.loc[cardiac_mask, \"cpet_cardiacimpairment\"] = 1\n",
    "\n",
    "print(\"\\n--- Results ---\")\n",
    "print(redcap[[\"cpet_gasexchangeimpairment\", \"cpet_ventilationimpairment\", \"cpet_cardiacimpairment\"]].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710b9af8",
   "metadata": {},
   "source": [
    "## PetCo2 Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1c129980",
   "metadata": {},
   "outputs": [],
   "source": [
    "redcap['cpet_petco2_change'] = redcap['cpet_petco2_peak'] - redcap['cpet_petco2_at_vslope']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488d3b30",
   "metadata": {},
   "source": [
    "# FMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0a1f03ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted FMD values: https://pubmed.ncbi.nlm.nih.gov/35709326/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a5cc69",
   "metadata": {},
   "source": [
    "# Autonomic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "30307723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable called autonomic_dysfunction that is 1 if all of the following conditions are met, otherwise 0: cpet_hr_restingsit > 75, (cpet_hr_peak - cpet_hr_restingsit) < 89, cpet_hrr1 < 25\n",
    "redcap['autonomic_dysfunction'] = np.where(\n",
    "    (redcap['cpet_hr_restingsit'] > 75) &\n",
    "    ((redcap['cpet_hr_peak'] - redcap['cpet_hr_restingsit']) < 89) &\n",
    "    (redcap['cpet_hrr1'] < 25),\n",
    "    1, 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976ecf78",
   "metadata": {},
   "source": [
    "# Subjective Questionnaires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dbc758",
   "metadata": {},
   "source": [
    "## Woods Mental Fatigue Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ffe75fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Woods Sum Statistics:\n",
      "Mean: 14.909090909090908\n",
      "Min: 0.0\n",
      "Max: 31.0\n",
      "Std: 9.174834595348761\n"
     ]
    }
   ],
   "source": [
    "# List of columns to sum\n",
    "woods_columns = [\n",
    "    'woods_concentration', 'woods_decisions', 'woods_confusion',\n",
    "    'woods_memory', 'woods_words', 'woods_takethingsin',\n",
    "    'woods_processingspeed', 'woods_thoughtsmixed', 'woods_muzzy'\n",
    "]\n",
    "\n",
    "# Create the new column 'woods_sum'\n",
    "redcap['woods_sum'] = redcap[woods_columns].sum(axis=1)\n",
    "\n",
    "# Display mean, min, max, and std of the 'woods_sum' column\n",
    "print(\"Woods Sum Statistics:\")\n",
    "print(f\"Mean: {redcap['woods_sum'].mean()}\")\n",
    "print(f\"Min: {redcap['woods_sum'].min()}\")\n",
    "print(f\"Max: {redcap['woods_sum'].max()}\")\n",
    "print(f\"Std: {redcap['woods_sum'].std()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20421467",
   "metadata": {},
   "source": [
    "## Fatigue Severity Scale (FSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d437bc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FSS Sum Statistics:\n",
      "Mean: 38.31818181818182\n",
      "Min: 10.0\n",
      "Max: 63.0\n",
      "Std: 16.55684040084933\n"
     ]
    }
   ],
   "source": [
    "# List of columns to sum\n",
    "fss_columns = ['fss_motivation', 'fss_exercise', 'fss_easily', 'fss_functioning',\n",
    "       'fss_problems', 'fss_sustained', 'fss_duties', 'fss_disabling',\n",
    "       'fss_social']\n",
    "\n",
    "# Create the new column 'fss_sum'\n",
    "redcap['fss_sum'] = redcap[fss_columns].sum(axis=1)\n",
    "\n",
    "# Create a new column fss_dichotomous if fss_sum is greater than 36\n",
    "redcap['fss_dichotomous'] = redcap['fss_sum'].apply(lambda x: 1 if x > 36 else 0)\n",
    "\n",
    "# Print the mean, min, max, and std of the 'fss_sum' column\n",
    "print(\"FSS Sum Statistics:\")\n",
    "print(f\"Mean: {redcap['fss_sum'].mean()}\")\n",
    "print(f\"Min: {redcap['fss_sum'].min()}\")\n",
    "print(f\"Max: {redcap['fss_sum'].max()}\")\n",
    "print(f\"Std: {redcap['fss_sum'].std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0ea231",
   "metadata": {},
   "source": [
    "## PEM (DSQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d85029cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSQ Dichotomous Frequency Counts:\n",
      "dsq_dichotomous\n",
      "1    26\n",
      "0    18\n",
      "Name: count, dtype: int64\n",
      "DSQ Sum Statistics:\n",
      "Mean: 14.454545454545455\n",
      "Min: 0.0\n",
      "Max: 38.0\n"
     ]
    }
   ],
   "source": [
    "# https://pmc.ncbi.nlm.nih.gov/articles/PMC6165517/\n",
    "# A frequency and severity score of 2, 2 on any items 1–5 is indicative of PEM.\n",
    "\n",
    "# Lists of columns\n",
    "freq_cols = [\n",
    "    'dsq_heavy_freq', 'dsq_nextday_freq', 'dsq_mentallytired_freq',\n",
    "    'dsq_minexercise_freq', 'dsq_drained_freq'\n",
    "]\n",
    "\n",
    "severity_cols = [\n",
    "    'dsq_heavy_severity', 'dsq_nextday_severity', 'dsq_mentallytired_severity',\n",
    "    'dsq_minexercise_severity', 'dsq_drained_severity'\n",
    "]\n",
    "\n",
    "# Sum of frequency\n",
    "redcap['dsq_freq_sum'] = redcap[freq_cols].sum(axis=1)\n",
    "\n",
    "# Sum of severity\n",
    "redcap['dsq_severity_sum'] = redcap[severity_cols].sum(axis=1)\n",
    "\n",
    "# Sum of both frequency and severity\n",
    "redcap['dsq_sum'] = redcap['dsq_freq_sum'] + redcap['dsq_severity_sum']\n",
    "\n",
    "# Dichotomous indicator (1 if any item has freq >=2 AND severity >=2)\n",
    "def compute_dsq_dichotomous(row):\n",
    "    for freq_col, sev_col in zip(freq_cols, severity_cols):\n",
    "        if (row[freq_col] >= 2) and (row[sev_col] >= 2):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "redcap['dsq_dichotomous'] = redcap.apply(compute_dsq_dichotomous, axis=1)\n",
    "\n",
    "# Print the frequency counts for dsq_dichotomous\n",
    "print(\"DSQ Dichotomous Frequency Counts:\")\n",
    "print(redcap['dsq_dichotomous'].value_counts())\n",
    "\n",
    "# Print the mean, min, max, and std of the 'dsq_sum' column\n",
    "print(\"DSQ Sum Statistics:\")\n",
    "print(f\"Mean: {redcap['dsq_sum'].mean()}\")\n",
    "print(f\"Min: {redcap['dsq_sum'].min()}\")\n",
    "print(f\"Max: {redcap['dsq_sum'].max()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4371a50",
   "metadata": {},
   "source": [
    "## Pittsburgh Sleep Index (PSQI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3ca86495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics for PSQI components and sum:\n",
      "      psqi_quality  psqi_latency  psqi_duration  psqi_efficiency  \\\n",
      "mean      1.363636      1.454545       0.977273         0.860465   \n",
      "min       0.000000      0.000000       0.000000         0.000000   \n",
      "max       3.000000      3.000000       3.000000         3.000000   \n",
      "\n",
      "      psqi_disturbances  psqi_medication  psqi_dysfunction  psqi_sum  \n",
      "mean                1.5         0.954545          1.159091      8.25  \n",
      "min                 0.0         0.000000          0.000000      1.00  \n",
      "max                 3.0         3.000000          3.000000     18.00  \n",
      "\n",
      "Frequency counts for psqi_dichotomous:\n",
      "psqi_dichotomous\n",
      "1    30\n",
      "0    14\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# If 'psqi_latency' currently holds raw minutes, just rename it to 'psqi_latency_raw'\n",
    "redcap['psqi_latency_raw'] = redcap['psqi_latency']\n",
    "\n",
    "# Recode Q2 (raw latency in minutes) into 0-3 scale\n",
    "def recode_q2(x):\n",
    "    if pd.isnull(x):\n",
    "        return np.nan\n",
    "    elif x < 15:\n",
    "        return 0\n",
    "    elif 15 <= x <= 30:\n",
    "        return 1\n",
    "    elif 31 <= x <= 60:\n",
    "        return 2\n",
    "    else:  # > 60 minutes\n",
    "        return 3\n",
    "\n",
    "redcap['psqi_latency_q2'] = redcap['psqi_latency_raw'].apply(recode_q2)\n",
    "\n",
    "# Q5a is already coded as 0-3, keep it as is in 'psqi_latency30'\n",
    "redcap['psqi_latency_q5a'] = redcap['psqi_latency30']\n",
    "\n",
    "# Sum the two recoded latency subscores\n",
    "redcap['psqi_latency_sum'] = redcap[['psqi_latency_q2', 'psqi_latency_q5a']].sum(axis=1)\n",
    "\n",
    "# Map the summed value into the final component score\n",
    "def map_latency_component(x):\n",
    "    if pd.isnull(x):\n",
    "        return np.nan\n",
    "    elif x == 0:\n",
    "        return 0\n",
    "    elif 1 <= x <= 2:\n",
    "        return 1\n",
    "    elif 3 <= x <= 4:\n",
    "        return 2\n",
    "    else:  # 5-6\n",
    "        return 3\n",
    "\n",
    "redcap['psqi_latency'] = redcap['psqi_latency_sum'].apply(map_latency_component)\n",
    "\n",
    "# 3. Sleep Duration\n",
    "def score_sleep_duration(hours):\n",
    "    if hours >= 7:\n",
    "        return 0\n",
    "    elif 6 <= hours < 7:\n",
    "        return 1\n",
    "    elif 5 <= hours < 6:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "redcap['psqi_duration'] = redcap['psqi_hours'].apply(score_sleep_duration)\n",
    "\n",
    "# 4. Sleep Efficiency\n",
    "def hhmm_to_decimal(time_val):\n",
    "    \"\"\"\n",
    "    Converts HHMM integer to decimal hours.\n",
    "    E.g. 2230 -> 22 + 30/60 = 22.5\n",
    "    \"\"\"\n",
    "    if pd.isnull(time_val):\n",
    "        return np.nan\n",
    "    hours = time_val // 100\n",
    "    minutes = time_val % 100\n",
    "    return hours + minutes / 60.0\n",
    "\n",
    "# --- Convert psqi_sleepstart and psqi_sleepend to decimal hours ---\n",
    "redcap['sleepstart_decimal'] = redcap['psqi_sleepstart'].apply(hhmm_to_decimal)\n",
    "redcap['sleepend_decimal'] = redcap['psqi_sleepend'].apply(hhmm_to_decimal)\n",
    "\n",
    "# --- Calculate Time in Bed (handling overnight shifts) ---\n",
    "def calculate_time_in_bed(start, end):\n",
    "    if pd.isnull(start) or pd.isnull(end):\n",
    "        return np.nan\n",
    "    time_in_bed = end - start\n",
    "    if time_in_bed <= 0:\n",
    "        time_in_bed += 24\n",
    "    return time_in_bed\n",
    "\n",
    "redcap['time_in_bed'] = redcap.apply(\n",
    "    lambda row: calculate_time_in_bed(row['sleepstart_decimal'], row['sleepend_decimal']), axis=1\n",
    ")\n",
    "\n",
    "# --- Calculate Sleep Efficiency ---\n",
    "redcap['sleep_efficiency'] = (redcap['psqi_hours'] / redcap['time_in_bed']) * 100\n",
    "\n",
    "# --- Score PSQI Component 4: Habitual Sleep Efficiency ---\n",
    "def score_sleep_efficiency(efficiency):\n",
    "    if pd.isnull(efficiency):\n",
    "        return np.nan\n",
    "    elif efficiency >= 85:\n",
    "        return 0\n",
    "    elif 75 <= efficiency < 85:\n",
    "        return 1\n",
    "    elif 65 <= efficiency < 75:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "redcap['psqi_efficiency'] = redcap['sleep_efficiency'].apply(score_sleep_efficiency)\n",
    "\n",
    "# 5. Sleep Disturbances\n",
    "disturbance_items = [\n",
    "    'psqi_wake', 'psqi_bathroom', 'psqi_breathe', 'psqi_snore',\n",
    "    'psqi_cold', 'psqi_hot', 'psqi_dreams', 'psqi_pain', 'psqi_other'\n",
    "]\n",
    "\n",
    "# TEMPORARY FIX: NEED TO REMOVE LATER AND FIX DATA ENTRY\n",
    "redcap['psqi_other'] = pd.to_numeric(redcap['psqi_other'], errors='coerce').fillna(0)\n",
    "\n",
    "redcap['psqi_disturbances_raw'] = redcap[disturbance_items].sum(axis=1)\n",
    "\n",
    "redcap['psqi_disturbances'] = pd.cut(\n",
    "    redcap['psqi_disturbances_raw'],\n",
    "    bins=[-1, 0, 9, 18, 27],  # Adjusted bins\n",
    "    labels=[0, 1, 2, 3]\n",
    ").astype(int)\n",
    "\n",
    "\n",
    "# 6. Use of Sleep Medications\n",
    "redcap['psqi_medication'] = redcap['psqi_medicine']\n",
    "\n",
    "# 7. Daytime Dysfunction\n",
    "redcap['psqi_dysfunction_raw'] = redcap[['psqi_sleepy', 'psqi_enthusiasm']].sum(axis=1)\n",
    "redcap['psqi_dysfunction'] = pd.cut(\n",
    "    redcap['psqi_dysfunction_raw'],\n",
    "    bins=[-1, 0, 2, 4, 6],\n",
    "    labels=[0, 1, 2, 3]\n",
    ").astype(int)\n",
    "\n",
    "# 8. Calculate PSQI Sum\n",
    "component_cols = [\n",
    "    'psqi_quality', 'psqi_latency', 'psqi_duration', \n",
    "    'psqi_efficiency', 'psqi_disturbances', \n",
    "    'psqi_medication', 'psqi_dysfunction'\n",
    "]\n",
    "redcap['psqi_sum'] = redcap[component_cols].sum(axis=1)\n",
    "\n",
    "# 9. Dichotomous classification: 0 = Good sleep, 1 = Poor sleep\n",
    "# https://www.psychiatry.pitt.edu/sites/default/files/inline-files/PSQI%20Article.pdf\n",
    "# https://pmc.ncbi.nlm.nih.gov/articles/PMC11973415/\n",
    "redcap['psqi_dichotomous'] = (redcap['psqi_sum'] > 5).astype(int)\n",
    "\n",
    "\n",
    "# List of all component columns plus the sum\n",
    "components = [\n",
    "    'psqi_quality', 'psqi_latency', 'psqi_duration', 'psqi_efficiency',\n",
    "    'psqi_disturbances', 'psqi_medication', 'psqi_dysfunction', 'psqi_sum'\n",
    "]\n",
    "\n",
    "# Summary stats: mean, min, max\n",
    "summary_stats = redcap[components].agg(['mean', 'min', 'max'])\n",
    "print(\"Summary statistics for PSQI components and sum:\")\n",
    "print(summary_stats)\n",
    "\n",
    "# Frequency counts for the dichotomous variable\n",
    "dichotomous_counts = redcap['psqi_dichotomous'].value_counts(dropna=False)\n",
    "print(\"\\nFrequency counts for psqi_dichotomous:\")\n",
    "print(dichotomous_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98899b0",
   "metadata": {},
   "source": [
    "## Dyspnea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "033a9869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute BDI Score\n",
    "redcap['bdi_sum'] = redcap[['bdi_functional', 'bdi_task', 'bdi_effort']].sum(axis=1)\n",
    "\n",
    "# Compute TDI Score\n",
    "redcap['tdi_sum'] = redcap[['tdi_functional', 'tdi_task', 'tdi_effort']].sum(axis=1)\n",
    "\n",
    "# Create dichotomous mmrc_dichotomous (1 if mmrc_grade >=2 else 0)\n",
    "# https://pubmed.ncbi.nlm.nih.gov/34670858/\n",
    "# https://pmc.ncbi.nlm.nih.gov/articles/PMC4541543/\n",
    "# https://publications.ersnet.org/content/erjor/9/6/00592-2023\n",
    "# https://journalpulmonology.org/en-the-copd-assessment-test-modified-articulo-S2531043721001197\n",
    "redcap['mmrc_dichotomous'] = redcap['mmrc_score'].apply(lambda x: 1 if x >= 2 else 0 if pd.notnull(x) else np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855d4f60",
   "metadata": {},
   "source": [
    "## ODI / NDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "01837625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum ODI columns\n",
    "odi_cols = [\n",
    "    'odi_intensity', 'odi_personalcare', 'odi_lifting', 'odi_walking',\n",
    "    'odi_sitting', 'odi_standing', 'odi_sleeping', 'odi_sex',\n",
    "    'odi_social', 'odi_traveling'\n",
    "]\n",
    "redcap['odi_sum'] = redcap[odi_cols].sum(axis=1, skipna=True)\n",
    "\n",
    "# Sum NDI columns\n",
    "ndi_cols = [\n",
    "    'ndi_intensity', 'ndi_personalcare', 'ndi_lifting', 'ndi_work',\n",
    "    'ndi_headaches', 'ndi_concentration', 'ndi_sleeping',\n",
    "    'ndi_driving', 'ndi_reading', 'ndi_recreation'\n",
    "]\n",
    "redcap['ndi_sum'] = redcap[ndi_cols].sum(axis=1, skipna=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9995ba2",
   "metadata": {},
   "source": [
    "## Psychology Questionnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "70bd1474",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ZCooper\\AppData\\Local\\Temp\\ipykernel_23360\\3429339521.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  redcap['ptsd_dichotomous'] = (redcap['ptsd_sum'] >= 3).astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Define the columns for each measure\n",
    "anxiety_cols = ['gad_anxious', 'gad_worrying']\n",
    "depression_cols = ['phq_hopeless', 'phq_anhedonia']\n",
    "ptsd_cols = ['ptsd_nightmares', 'ptsd_intrusive', 'ptsd_startled', 'ptsd_detached', 'ptsd_guilty']\n",
    "\n",
    "# Calculate sum scores\n",
    "redcap['anxiety_sum'] = redcap[anxiety_cols].sum(axis=1, skipna=True)\n",
    "redcap['depression_sum'] = redcap[depression_cols].sum(axis=1, skipna=True)\n",
    "redcap['ptsd_sum'] = redcap[ptsd_cols].sum(axis=1, skipna=True)\n",
    "\n",
    "# Create dichotomous variables\n",
    "# PTSD-5: 3 most sensitive, 5 most specific, 4 most efficient https://pmc.ncbi.nlm.nih.gov/articles/PMC5023594/ \n",
    "# PHq-2: >=2 --> https://pubmed.ncbi.nlm.nih.gov/33026888/, https://jamanetwork.com/journals/jama/fullarticle/2766865\n",
    "# GAD-2: >=3 --> https://www.sciencedirect.com/science/article/abs/pii/S0003999318303903, https://www.sciencedirect.com/science/article/abs/pii/S0163834315002406, https://pmc.ncbi.nlm.nih.gov/articles/PMC6163062/, https://pmc.ncbi.nlm.nih.gov/articles/PMC7306644/\n",
    "redcap['anxiety_dichotomous'] = (redcap['anxiety_sum'] >= 3).astype(int)\n",
    "redcap['depression_dichotomous'] = (redcap['depression_sum'] >= 2).astype(int)\n",
    "redcap['ptsd_dichotomous'] = (redcap['ptsd_sum'] >= 3).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e75c29",
   "metadata": {},
   "source": [
    "## SF-PA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "10bda6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ZCooper\\AppData\\Local\\Temp\\ipykernel_23360\\1787994129.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  redcap['sfpa_sum'] = (\n"
     ]
    }
   ],
   "source": [
    "# Define the columns for SFPA\n",
    "sfpa_cols = [\n",
    "    'sfpa_vigorous', 'sfpa_moderate', 'sfpa_lifting',\n",
    "    'sfpa_stairs2', 'sfpa_stairs1', 'sfpa_stooping',\n",
    "    'sfpa_walkingmile', 'sfpa_walkingblocks2',\n",
    "    'sfpa_walkingblocks1', 'sfpa_bathingdress'\n",
    "]\n",
    "\n",
    "# Recode and calculate in one step using replace()\n",
    "# https://www.physio-pedia.com/36-Item_Short_Form_Survey_(SF-36)\n",
    "redcap['sfpa_sum'] = (\n",
    "    redcap[sfpa_cols]\n",
    "    .replace({1: 0, 2: 50, 3: 100})\n",
    "    .sum(axis=1, skipna=True) \n",
    "    / 10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8d27c3",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "73c1fa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for time_point = 1\n",
    "df_CS = redcap[redcap['time_point'] == 1].copy()\n",
    "\n",
    "# Create DataFrame for Covid_group = 1\n",
    "df_RCT = redcap[redcap['covid_group'] == 1].copy()\n",
    "\n",
    "# Export to CSV files\n",
    "df_CS.to_csv('df_CS.csv', index=False)\n",
    "df_RCT.to_csv('df_RCT.csv', index=False)\n",
    "redcap.to_csv('df_full.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
